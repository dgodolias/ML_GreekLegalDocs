{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Μέρος Β1.iii: Ταξινόμηση Νομικών Εγγράφων με XGBoost και Word2Vec\n",
    "\n",
    "Αυτό το notebook αφορά την υλοποίηση και αξιολόγηση μοντέλων XGBoost για την ταξινόμηση ελληνικών νομικών εγγράφων, χρησιμοποιώντας πυκνές αναπαραστάσεις κειμένου (dense embeddings) που προέρχονται από το Word2Vec. Η εργασία αυτή αποτελεί μέρος του ερωτήματος Β1.iii της εξαμηνιαίας εργασίας."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Το παραπάνω κελί Markdown εισάγει τον σκοπό του notebook: την εφαρμογή XGBoost με Word2Vec embeddings για την ταξινόμηση νομικών κειμένων, σύμφωνα με τις απαιτήσεις του Β1.iii."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Σύντομη Επισκόπηση: XGBoost με Word2Vec\n",
    "\n",
    "Το XGBoost (Extreme Gradient Boosting) είναι ένας ισχυρός και ευρέως χρησιμοποιούμενος αλγόριθμος μηχανικής μάθησης που βασίζεται στην τεχνική gradient boosting. Είναι γνωστός για την υψηλή του απόδοση και την ταχύτητά του.\n",
    "\n",
    "Σε αυτό το πλαίσιο, συνδυάζουμε το XGBoost με Word2Vec embeddings:\n",
    "1.  **Word2Vec Embeddings:** Τα νομικά κείμενα μετατρέπονται πρώτα σε πυκνά διανύσματα (document embeddings) χρησιμοποιώντας ένα προ-εκπαιδευμένο ή εκπαιδευμένο επί τόπου μοντέλο Word2Vec. Συνήθως, αυτό γίνεται παίρνοντας τον μέσο όρο των word embeddings των λέξεων κάθε εγγράφου.\n",
    "2.  **XGBoost Classifier:** Αυτά τα document embeddings χρησιμοποιούνται στη συνέχεια ως χαρακτηριστικά εισόδου για την εκπαίδευση ενός ταξινομητή XGBoost.\n",
    "\n",
    "Ο συνδυασμός αυτός αξιοποιεί την ικανότητα του Word2Vec να συλλαμβάνει σημασιολογικές πληροφορίες και την ισχύ του XGBoost στην ταξινόμηση."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Αυτό το κελί Markdown παρέχει μια πολύ σύντομη επισκόπηση του XGBoost και του πώς συνδυάζεται με το Word2Vec για την ταξινόμηση κειμένου."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Υλοποίηση και Πειράματα"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Αυτό το κελί Markdown σηματοδοτεί την έναρξη της ενότητας υλοποίησης και πειραμάτων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\PROJECTS\\ML_GreekLegalDocs\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported from utils.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import xgboost as xgb # Βιβλιοθήκη XGBoost\n",
    "\n",
    "# Προσθήκη του γονικού καταλόγου στο path για την εισαγωγή του utils.py\n",
    "current_notebook_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_notebook_dir)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "try:\n",
    "    from utils import (\n",
    "        load_and_preprocess_data,\n",
    "        run_experiment, # Αυτή η συνάρτηση χειρίζεται και το Word2Vec feature generation\n",
    "        script_execution_timer\n",
    "    )\n",
    "    print(\"Successfully imported from utils.py\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing from utils.py: {e}\")\n",
    "    print(f\"Please ensure utils.py is in the correct path: {parent_dir} or that the notebook's parent directory is correctly identified.\")\n",
    "\n",
    "# Η import της Word2Vec γίνεται μέσα στο utils.py όταν χρειάζεται"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Το παραπάνω κελί κώδικα εισάγει τις απαραίτητες βιβλιοθήκες Python (sys, os, numpy, xgboost) και ρυθμίζει το `sys.path` για την εισαγωγή των συναρτήσεων από το `utils.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Ρυθμίσεις Πειράματος\n",
    "\n",
    "Παρακαλώ επιλέξτε τις παραμέτρους για το πείραμα."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Αυτό το κελί Markdown εισάγει την ενότητα όπου ο χρήστης μπορεί να διαμορφώσει τις παραμέτρους του πειράματος."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: For 'volume' target, typically 5-fold CV was used in the report. Adjust N_SPLITS_CV if needed.\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "# Επιλέξτε την ετικέτα-στόχο: \"volume\", \"chapter\", ή \"subject\"\n",
    "DATASET_CONFIG = \"volume\" \n",
    "\n",
    "# Ποσοστό του dataset που θα χρησιμοποιηθεί\n",
    "SUBSET_PERCENTAGE = 0.1 # Για λόγους ταχύτητας. Αλλάξτε σε 1.0 για πλήρη δεδομένα.\n",
    "\n",
    "# Αριθμός K-folds για Cross-Validation (1 για απλό train/test split)\n",
    "N_SPLITS_CV = 1 \n",
    "if DATASET_CONFIG == \"volume\":\n",
    "    print(\"INFO: For 'volume' target, typically 5-fold CV was used in the report. Adjust N_SPLITS_CV if needed.\")\n",
    "    # N_SPLITS_CV = 5 # Uncomment to match report for 'volume'\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "SINGLE_SPLIT_TEST_SIZE = 0.2\n",
    "\n",
    "SAVE_TRAINED_FEATURE_MODELS = True\n",
    "LOAD_TRAINED_FEATURE_MODELS_IF_EXIST = True\n",
    "\n",
    "# Word2Vec parameters (όπως στην αναφορά)\n",
    "WORD2VEC_VECTOR_SIZE = 100\n",
    "WORD2VEC_WINDOW = 5\n",
    "WORD2VEC_MIN_COUNT = 2\n",
    "WORD2VEC_WORKERS = 4 \n",
    "WORD2VEC_SG = 0      # CBOW\n",
    "WORD2VEC_EPOCHS = 10\n",
    "\n",
    "# XGBoost parameters (όπως στην αναφορά)\n",
    "XGB_N_ESTIMATORS = 100\n",
    "XGB_LEARNING_RATE = 0.1\n",
    "XGB_MAX_DEPTH = 3\n",
    "XGB_EVAL_METRIC = 'mlogloss' # mlogloss για multi-class classification\n",
    "# --- End Configuration ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Αυτό το κελί κώδικα περιέχει τις παραμέτρους διαμόρφωσης για το πείραμα XGBoost με Word2Vec, συμπεριλαμβανομένων των ρυθμίσεων για το dataset, το Word2Vec και το XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@script_execution_timer\n",
    "def run_xgboost_w2v_experiment(dataset_config, subset_percentage, n_splits_cv, random_state, \n",
    "                               single_split_test_size, save_feature_models, load_feature_models,\n",
    "                               w2v_vector_size, w2v_window, w2v_min_count, w2v_workers, w2v_sg, w2v_epochs,\n",
    "                               xgb_n_estimators, xgb_learning_rate, xgb_max_depth, xgb_eval_metric):\n",
    "    model_name_script = \"XGBoost\"\n",
    "    feature_method_name = \"Word2Vec\"\n",
    "    \n",
    "    base_run_id = f\"{model_name_script}_{feature_method_name}_{dataset_config}\"\n",
    "    \n",
    "    print(f\"Starting {model_name_script} with {feature_method_name} for '{dataset_config}' config...\")\n",
    "    \n",
    "    feature_config = {\n",
    "        'method': 'word2vec',\n",
    "        'params': {\n",
    "            'vector_size': w2v_vector_size,\n",
    "            'window': w2v_window,\n",
    "            'min_count': w2v_min_count,\n",
    "            'workers': w2v_workers,\n",
    "            'sg': w2v_sg,\n",
    "            'epochs': w2v_epochs,\n",
    "            'seed': random_state\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    model_class = xgb.XGBClassifier\n",
    "    model_init_params = {\n",
    "        'n_estimators': xgb_n_estimators,\n",
    "        'learning_rate': xgb_learning_rate,\n",
    "        'max_depth': xgb_max_depth,\n",
    "        'eval_metric': xgb_eval_metric,\n",
    "        'random_state': random_state,\n",
    "        # 'use_label_encoder': False # For newer XGBoost versions, this is often handled automatically or not needed if labels are 0 to N-1\n",
    "    }\n",
    "\n",
    "    script_dir = os.getcwd()\n",
    "    experiment_output_base_dir = os.path.join(script_dir, \"outputs\", base_run_id)\n",
    "    reports_output_dir = os.path.join(experiment_output_base_dir, \"reports\")\n",
    "    feature_models_output_dir = os.path.join(experiment_output_base_dir, \"feature_models\")\n",
    "    \n",
    "    os.makedirs(reports_output_dir, exist_ok=True)\n",
    "    os.makedirs(feature_models_output_dir, exist_ok=True)\n",
    "    print(f\"INFO: Experiment outputs will be saved in '{experiment_output_base_dir}'\")\n",
    "\n",
    "    if 0 < subset_percentage < 1.0:\n",
    "        print(f\"INFO: Using a {subset_percentage*100:.0f}% subset of the data.\")\n",
    "    else:\n",
    "        print(\"INFO: Using all available data (after filtering).\")\n",
    "    \n",
    "    if n_splits_cv == 1:\n",
    "        print(f\"INFO: Performing a single train/test split (test_size={single_split_test_size}).\")\n",
    "    elif n_splits_cv > 1:\n",
    "        print(f\"INFO: Performing {n_splits_cv}-Fold Cross-Validation.\")\n",
    "    else:\n",
    "        print(\"ERROR: N_SPLITS_CV must be >= 1.\")\n",
    "        return\n",
    "\n",
    "    texts_proc, labels_proc, unique_labels_proc, unique_labels_proc_str = load_and_preprocess_data(\n",
    "        dataset_config, subset_percentage, random_state\n",
    "    )\n",
    "\n",
    "    if texts_proc is None or len(texts_proc) == 0:\n",
    "        print(\"Failed to load or preprocess data. Exiting.\")\n",
    "        return\n",
    "\n",
    "    success = run_experiment(\n",
    "        texts_to_process=texts_proc,\n",
    "        labels_to_process=labels_proc,\n",
    "        unique_labels_to_process=unique_labels_proc,\n",
    "        unique_labels_to_process_str=unique_labels_proc_str,\n",
    "        n_splits=n_splits_cv,\n",
    "        feature_config=feature_config,\n",
    "        model_class=model_class,\n",
    "        model_init_params=model_init_params,\n",
    "        base_run_identifier=base_run_id, \n",
    "        reports_output_dir=reports_output_dir,\n",
    "        feature_models_output_dir=feature_models_output_dir,\n",
    "        random_state=random_state,\n",
    "        save_trained_features=save_feature_models,\n",
    "        load_trained_features_if_exist=load_feature_models,\n",
    "        single_split_test_size=single_split_test_size\n",
    "    )\n",
    "\n",
    "    if success:\n",
    "        print(f\"\\nExperiment '{base_run_id}' completed successfully.\")\n",
    "    else:\n",
    "        print(f\"\\nExperiment '{base_run_id}' encountered errors.\")\n",
    "\n",
    "    print(f\"\\n{model_name_script} with {feature_method_name} script finished for {dataset_config} dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Αυτό το κελί κώδικα ορίζει τη συνάρτηση `run_xgboost_w2v_experiment`. Αυτή η συνάρτηση ενσωματώνει τη λογική για την εκτέλεση ενός πειράματος XGBoost με Word2Vec, καλώντας τις γενικές συναρτήσεις από το `utils.py` για τη διαχείριση δεδομένων, χαρακτηριστικών και εκτέλεσης του μοντέλου."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Εκτέλεση Πειράματος\n",
    "\n",
    "Το παρακάτω κελί θα εκτελέσει το πείραμα."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Αυτό το κελί Markdown εισάγει το κελί κώδικα που θα εκτελέσει το πείραμα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Script 'run_xgboost_w2v_experiment' started at: 2025-05-24 20:30:39 ---\n",
      "Starting XGBoost with Word2Vec for 'volume' config...\n",
      "INFO: Experiment outputs will be saved in 'c:\\Users\\USER\\Desktop\\PROJECTS\\ML_GreekLegalDocs\\merosB1\\outputs\\XGBoost_Word2Vec_volume'\n",
      "INFO: Using a 10% subset of the data.\n",
      "INFO: Performing a single train/test split (test_size=0.2).\n",
      "Loading dataset 'AI-team-UoA/greek_legal_code' with 'volume' configuration...\n",
      "Dataset loaded in 6.66 seconds.\n",
      "Extracting text and labels...\n",
      "Full dataset extracted in 0.52s. Samples: 28536\n",
      "Original unique labels in full dataset (volume config): 47\n",
      "Filtering out classes with fewer than 2 samples...\n",
      "No classes needed filtering based on min_samples_per_class.\n",
      "Dataset size after filtering for min_samples_per_class: 28536 samples.\n",
      "Unique labels after initial filtering: 47\n",
      "\n",
      "Selecting a 10% subset from the filtered data...\n",
      "Subset size: 2853\n",
      "Unique labels in data finally selected for processing: 47\n",
      "\n",
      "--- Performing single train/test split (80%/20%) for XGBoost_Word2Vec_volume ---\n",
      "Data split. Train texts: 2282, Test texts: 571\n",
      "Training Word2Vec model...\n",
      "Saving Word2Vec model to c:\\Users\\USER\\Desktop\\PROJECTS\\ML_GreekLegalDocs\\merosB1\\outputs\\XGBoost_Word2Vec_volume\\feature_models\\word2vec_XGBoost_Word2Vec_volume_single_run.model...\n",
      "Training XGBClassifier classifier...\n",
      "Making predictions on the test set...\n",
      "Accuracy on the test set: 0.1821\n",
      "\n",
      "Classification Report for XGBoost_Word2Vec_volume (Single Run):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class 0       0.00      0.00      0.00        11\n",
      "     Class 1       0.10      0.17      0.12        23\n",
      "     Class 2       0.00      0.00      0.00         5\n",
      "     Class 3       0.00      0.00      0.00        15\n",
      "     Class 4       0.12      0.10      0.11        21\n",
      "     Class 5       0.25      0.14      0.18         7\n",
      "     Class 6       0.17      0.08      0.11        13\n",
      "     Class 7       0.00      0.00      0.00         7\n",
      "     Class 8       0.00      0.00      0.00         5\n",
      "     Class 9       0.00      0.00      0.00         4\n",
      "    Class 10       0.12      0.10      0.11        10\n",
      "    Class 11       0.22      0.18      0.20        11\n",
      "    Class 12       0.00      0.00      0.00         5\n",
      "    Class 13       0.17      0.11      0.13         9\n",
      "    Class 14       0.00      0.00      0.00        10\n",
      "    Class 15       0.00      0.00      0.00         9\n",
      "    Class 16       0.00      0.00      0.00         6\n",
      "    Class 17       0.14      0.17      0.15        18\n",
      "    Class 18       0.08      0.10      0.09        21\n",
      "    Class 19       0.45      0.59      0.51        17\n",
      "    Class 20       0.50      0.12      0.20         8\n",
      "    Class 21       0.19      0.31      0.23        35\n",
      "    Class 22       0.50      0.14      0.22         7\n",
      "    Class 23       0.14      0.08      0.11        12\n",
      "    Class 24       0.21      0.29      0.24        28\n",
      "    Class 25       0.20      0.22      0.21        18\n",
      "    Class 26       0.10      0.10      0.10        10\n",
      "    Class 27       0.00      0.00      0.00         6\n",
      "    Class 28       0.20      0.15      0.17        13\n",
      "    Class 29       0.00      0.00      0.00         7\n",
      "    Class 30       1.00      0.25      0.40         8\n",
      "    Class 31       0.00      0.00      0.00        12\n",
      "    Class 32       0.17      0.17      0.17         6\n",
      "    Class 33       0.00      0.00      0.00         3\n",
      "    Class 34       0.24      0.29      0.26        14\n",
      "    Class 35       0.00      0.00      0.00         7\n",
      "    Class 36       0.12      0.07      0.09        14\n",
      "    Class 37       0.00      0.00      0.00         8\n",
      "    Class 38       0.00      0.00      0.00         6\n",
      "    Class 39       0.12      0.18      0.14        11\n",
      "    Class 40       0.00      0.00      0.00         5\n",
      "    Class 41       0.10      0.20      0.13        15\n",
      "    Class 42       0.00      0.00      0.00         7\n",
      "    Class 43       0.00      0.00      0.00         7\n",
      "    Class 44       0.35      0.62      0.44        42\n",
      "    Class 45       0.40      0.36      0.38        22\n",
      "    Class 46       0.11      0.08      0.09        13\n",
      "\n",
      "    accuracy                           0.18       571\n",
      "   macro avg       0.14      0.11      0.11       571\n",
      "weighted avg       0.17      0.18      0.16       571\n",
      "\n",
      "Single run classification report (TXT) saved to c:\\Users\\USER\\Desktop\\PROJECTS\\ML_GreekLegalDocs\\merosB1\\outputs\\XGBoost_Word2Vec_volume\\reports\\classification_report_XGBoost_Word2Vec_volume_single_run.txt\n",
      "Single run classification report (JSON) saved to c:\\Users\\USER\\Desktop\\PROJECTS\\ML_GreekLegalDocs\\merosB1\\outputs\\XGBoost_Word2Vec_volume\\reports\\classification_report_XGBoost_Word2Vec_volume_single_run.json\n",
      "\n",
      "Experiment 'XGBoost_Word2Vec_volume' completed successfully.\n",
      "\n",
      "XGBoost with Word2Vec script finished for volume dataset.\n",
      "--- Script 'run_xgboost_w2v_experiment' finished at: 2025-05-24 20:30:57 ---\n",
      "--- Total execution time for 'run_xgboost_w2v_experiment': 18.83 seconds ---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_xgboost_w2v_experiment(\n",
    "    dataset_config=DATASET_CONFIG,\n",
    "    subset_percentage=SUBSET_PERCENTAGE,\n",
    "    n_splits_cv=N_SPLITS_CV,\n",
    "    random_state=RANDOM_STATE,\n",
    "    single_split_test_size=SINGLE_SPLIT_TEST_SIZE,\n",
    "    save_feature_models=SAVE_TRAINED_FEATURE_MODELS,\n",
    "    load_feature_models=LOAD_TRAINED_FEATURE_MODELS_IF_EXIST,\n",
    "    w2v_vector_size=WORD2VEC_VECTOR_SIZE,\n",
    "    w2v_window=WORD2VEC_WINDOW,\n",
    "    w2v_min_count=WORD2VEC_MIN_COUNT,\n",
    "    w2v_workers=WORD2VEC_WORKERS,\n",
    "    w2v_sg=WORD2VEC_SG,\n",
    "    w2v_epochs=WORD2VEC_EPOCHS,\n",
    "    xgb_n_estimators=XGB_N_ESTIMATORS,\n",
    "    xgb_learning_rate=XGB_LEARNING_RATE,\n",
    "    xgb_max_depth=XGB_MAX_DEPTH,\n",
    "    xgb_eval_metric=XGB_EVAL_METRIC\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Αυτό το κελί κώδικα εκτελεί το πείραμα καλώντας τη συνάρτηση `run_xgboost_w2v_experiment` με τις παραμέτρους που ορίστηκαν προηγουμένως."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Αποτελέσματα και Σχολιασμός\n",
    "\n",
    "Τα αναλυτικά αποτελέσματα (classification reports) αποθηκεύονται στον κατάλογο `outputs/[MODEL_FEATURE_CONFIG]/reports/`.\n",
    "\n",
    "Για παράδειγμα:\n",
    "`merosB1/iii/outputs/XGBoost_Word2Vec_subject/reports/`\n",
    "\n",
    "Τα αποτελέσματα στην επιστημονική αναφορά (`B1.md`) για XGBoost+W2V προέρχονται από εκτελέσεις αυτού του κώδικα."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Αυτό το τελικό κελί Markdown παρέχει πληροφορίες για το πού αποθηκεύονται τα αποτελέσματα του πειράματος."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
