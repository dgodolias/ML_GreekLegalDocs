{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Μέρος Β1.i: Ταξινόμηση Νομικών Εγγράφων με Support Vector Machines (SVM) \n",
    "\n",
    "Αυτό το notebook αφορά την υλοποίηση και αξιολόγηση μοντέλων Support Vector Machines (SVM) για την ταξινόμηση ελληνικών νομικών εγγράφων, χρησιμοποιώντας αναπαραστάσεις κειμένου Bag-of-Words (BoW) και TF-IDF. Η εργασία αυτή αποτελεί μέρος του ερωτήματος Β1.i της εξαμηνιαίας εργασίας."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e803e2cf",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Εισαγωγή στο notebook: SVM με BoW/TF-IDF για ταξινόμηση νομικών κειμένων (Β1.i)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068c52b4",
   "metadata": {},
   "source": [
    "## 1. Τεχνική Ανάλυση Αλγορίθμων\n",
    "\n",
    "### 1.1. Μηχανές Υποστήριξης Διανυσμάτων (Support Vector Machines - SVM)\n",
    "\n",
    "Οι SVMs βρίσκουν ένα βέλτιστο υπερεπίπεδο που διαχωρίζει κλάσεις μεγιστοποιώντας το περιθώριο μεταξύ τους. Χρησιμοποιούνται για ταξινόμηση.\n",
    "\n",
    "**Βασικά Σημεία:**\n",
    "- **Υπερεπίπεδο & Περιθώριο:** Στόχος είναι το υπερεπίπεδο με το μεγαλύτερο περιθώριο.\n",
    "- **Διανύσματα Υποστήριξης:** Σημεία δεδομένων που καθορίζουν το υπερεπίπεδο.\n",
    "- **Πυρήνες (Kernels):** Για μη γραμμικά διαχωρίσιμα δεδομένα (π.χ., 'linear', 'rbf', 'poly'). Χρησιμοποιήθηκε 'linear'.\n",
    "- **Παράμετρος `C`:** Ελέγχει τον συμβιβασμό μεταξύ μεγιστοποίησης περιθωρίου και ελαχιστοποίησης σφαλμάτων ταξινόμησης. Χρησιμοποιήθηκε `C=1.0`.\n",
    "- **Πλεονεκτήματα:** Αποτελεσματικά σε υψηλές διαστάσεις, αποδοτικά ως προς τη μνήμη.\n",
    "- **Μειονεκτήματα:** Αργά σε μεγάλα datasets, ευαίσθητα στην επιλογή πυρήνα/παραμέτρων."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84128c7a",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Συνοπτική τεχνική ανάλυση των SVM: βασική ιδέα, πυρήνες, παράμετρος C, πλεονεκτήματα και μειονεκτήματα."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2b6a0",
   "metadata": {},
   "source": [
    "### 1.2. Αναπαράσταση Κειμένου: Σάκος Λέξεων (Bag-of-Words - BoW)\n",
    "\n",
    "Το BoW αναπαριστά κείμενο ως ένα διάνυσμα συχνοτήτων λέξεων από ένα λεξιλόγιο.\n",
    "\n",
    "**Βασικά Σημεία:**\n",
    "- **Διαδικασία:** Δημιουργία λεξιλογίου, διανυσματοποίηση εγγράφων με βάση τις συχνότητες λέξεων.\n",
    "- **Παράμετροι (`CountVectorizer`):** `max_features` (μέγεθος λεξιλογίου, εδώ 5000), `stop_words`, `ngram_range`.\n",
    "- **Πλεονεκτήματα:** Απλότητα, αποδοτικότητα.\n",
    "- **Μειονεκτήματα:** Απώλεια σειράς λέξεων και σημασιολογίας, υψηλή διαστατικότητα/αραιότητα."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e02a4b",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Συνοπτική τεχνική ανάλυση του BoW: διαδικασία, παράμετροι, πλεονεκτήματα και μειονεκτήματα."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab96cf",
   "metadata": {},
   "source": [
    "### 1.3. Αναπαράσταση Κειμένου: TF-IDF (Term Frequency-Inverse Document Frequency)\n",
    "\n",
    "Το TF-IDF δίνει βάρος στις λέξεις ανάλογα με τη συχνότητά τους σε ένα έγγραφο (TF) και την αντιστρόφως ανάλογη συχνότητά τους στο σύνολο των εγγράφων (IDF).\n",
    "\n",
    "**Βασικά Σημεία:**\n",
    "- **TF (Term Frequency):** Συχνότητα όρου στο έγγραφο.\n",
    "- **IDF (Inverse Document Frequency):** Σημαντικότητα όρου στο σώμα κειμένων.\n",
    "- **TF-IDF Score:** `TF * IDF`. Υψηλό για όρους συχνούς στο έγγραφο αλλά σπάνιους γενικά.\n",
    "- **Παράμετροι (`TfidfVectorizer`):** Παρόμοιες με `CountVectorizer` (π.χ. `max_features=5000`), `use_idf`, `smooth_idf`, `norm`.\n",
    "- **Πλεονεκτήματα:** Μειώνει βάρος κοινών λέξεων, τονίζει χαρακτηριστικές λέξεις.\n",
    "- **Μειονεκτήματα:** Αγνοεί σειρά/σημασιολογία, αραιότητα."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfbd6a4",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Συνοπτική τεχνική ανάλυση του TF-IDF: συστατικά, score, παράμετροι, πλεονεκτήματα και μειονεκτήματα."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946bc9dc",
   "metadata": {},
   "source": [
    "### 1.4. Συνδυασμός SVM με BoW/TF-IDF\n",
    "\n",
    "Η διαδικασία συνδυασμού περιλαμβάνει:\n",
    "1.  **Προεπεξεργασία Κειμένου.**\n",
    "2.  **Εξαγωγή Χαρακτηριστικών** με BoW ή TF-IDF.\n",
    "3.  **Εκπαίδευση SVM** με τα διανύσματα χαρακτηριστικών.\n",
    "\n",
    "**Οφέλη:** Τα SVMs είναι αποτελεσματικά σε χώρους υψηλών διαστάσεων που παράγονται από BoW/TF-IDF. Το TF-IDF μπορεί να βελτιώσει την ποιότητα των χαρακτηριστικών."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caeaef6",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Περιγραφή του συνδυασμού SVM με BoW/TF-IDF: βήματα και οφέλη."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d86745",
   "metadata": {},
   "source": [
    "## 2. Υλοποίηση και Πειράματα\n",
    "\n",
    "Στα παρακάτω κελιά κώδικα, θα ρυθμίσουμε και θα εκτελέσουμε τα πειράματα ταξινόμησης χρησιμοποιώντας SVM με BoW και TF-IDF. Θα χρησιμοποιήσουμε τις συναρτήσεις από το αρχείο `utils.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c44077",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Έναρξη της ενότητας υλοποίησης και πειραμάτων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4a4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "current_notebook_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_notebook_dir)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "try:\n",
    "    from utils import (\n",
    "        load_and_preprocess_data,\n",
    "        run_experiment,\n",
    "        script_execution_timer\n",
    "    )\n",
    "    print(\"Successfully imported from utils.py\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing from utils.py: {e}\")\n",
    "    print(f\"Please ensure utils.py is in the correct path: {parent_dir} or that the notebook's parent directory is correctly identified.\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b55c731",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Εισαγωγή βιβλιοθηκών και ρύθμιση path για το `utils.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021c77b3",
   "metadata": {},
   "source": [
    "### 2.1. Ρυθμίσεις Πειράματος\n",
    "\n",
    "Παρακαλώ επιλέξτε τις παραμέτρους για το πείραμα. Μπορείτε να αλλάξετε τις τιμές των μεταβλητών στο παρακάτω κελί κώδικα."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6529daf5",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Ενότητα διαμόρφωσης παραμέτρων πειράματος."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c9c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration ---\n",
    "DATASET_CONFIG = \"volume\" \n",
    "FEATURE_METHOD = \"BoW\" # or \"TF-IDF\"\n",
    "SUBSET_PERCENTAGE = 0.1 \n",
    "N_SPLITS_CV = 1 \n",
    "RANDOM_STATE = 42\n",
    "VECTORIZER_MAX_FEATURES = 5000 \n",
    "SINGLE_SPLIT_TEST_SIZE = 0.2 \n",
    "SAVE_TRAINED_FEATURE_MODELS = True\n",
    "LOAD_TRAINED_FEATURE_MODELS_IF_EXIST = True\n",
    "# --- End Configuration ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f1a993",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Παράμετροι διαμόρφωσης για το πείραμα (dataset, feature method, split, vectorizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3758546f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@script_execution_timer\n",
    "def run_svm_experiment(dataset_config, feature_method, subset_percentage, n_splits_cv, random_state, vectorizer_max_features, single_split_test_size, save_models, load_models):\n",
    "    model_name_script = \"SVM\"\n",
    "    feature_method_name = feature_method\n",
    "    base_run_id = f\"{model_name_script}_{feature_method_name.replace('-', '')}_{dataset_config}\" \n",
    "    print(f\"Starting {model_name_script} with {feature_method_name} for '{dataset_config}' config...\")\n",
    "    \n",
    "    if feature_method_name == \"BoW\":\n",
    "        feature_config = {\n",
    "            'method': 'sklearn_vectorizer',\n",
    "            'class': CountVectorizer,\n",
    "            'params': {'max_features': vectorizer_max_features, 'stop_words': None}\n",
    "        }\n",
    "    elif feature_method_name == \"TF-IDF\":\n",
    "        feature_config = {\n",
    "            'method': 'sklearn_vectorizer',\n",
    "            'class': TfidfVectorizer,\n",
    "            'params': {'max_features': vectorizer_max_features, 'stop_words': None}\n",
    "        }\n",
    "    else:\n",
    "        print(f\"ERROR: Unknown feature_method: {feature_method_name}\")\n",
    "        return\n",
    "    \n",
    "    model_class = SVC\n",
    "    model_init_params = {'kernel': 'linear', 'probability': True, 'random_state': random_state, 'C': 1.0}\n",
    "\n",
    "    script_dir = os.getcwd()\n",
    "    experiment_output_base_dir = os.path.join(script_dir, \"outputs\", base_run_id)\n",
    "    reports_output_dir = os.path.join(experiment_output_base_dir, \"reports\")\n",
    "    feature_models_output_dir = os.path.join(experiment_output_base_dir, \"feature_models\")\n",
    "    os.makedirs(reports_output_dir, exist_ok=True)\n",
    "    os.makedirs(feature_models_output_dir, exist_ok=True)\n",
    "    print(f\"INFO: Experiment outputs will be saved in '{experiment_output_base_dir}'\")\n",
    "\n",
    "    if 0 < subset_percentage < 1.0:\n",
    "        print(f\"INFO: Using a {subset_percentage*100:.0f}% subset of the data.\")\n",
    "    else:\n",
    "        print(\"INFO: Using all available data (after filtering).\")\n",
    "    \n",
    "    if n_splits_cv == 1:\n",
    "        print(f\"INFO: Performing a single train/test split (test_size={single_split_test_size}).\")\n",
    "    elif n_splits_cv > 1:\n",
    "        print(f\"INFO: Performing {n_splits_cv}-Fold Cross-Validation.\")\n",
    "    else:\n",
    "        print(\"ERROR: N_SPLITS_CV must be >= 1.\")\n",
    "        return\n",
    "\n",
    "    print(f\"INFO: Saving of trained feature models is {'ENABLED' if save_models else 'DISABLED'}.\")\n",
    "    print(f\"INFO: Loading of existing feature models is {'ENABLED' if load_models else 'DISABLED'}.\")\n",
    "\n",
    "    texts_proc, labels_proc, unique_labels_proc, unique_labels_proc_str = load_and_preprocess_data(\n",
    "        dataset_config, subset_percentage, random_state\n",
    "    )\n",
    "\n",
    "    if texts_proc is None or len(texts_proc) == 0:\n",
    "        print(\"Failed to load or preprocess data. Exiting.\")\n",
    "        return\n",
    "\n",
    "    success = run_experiment(\n",
    "        texts_to_process=texts_proc,\n",
    "        labels_to_process=labels_proc,\n",
    "        unique_labels_to_process=unique_labels_proc,\n",
    "        unique_labels_to_process_str=unique_labels_proc_str,\n",
    "        n_splits=n_splits_cv,\n",
    "        feature_config=feature_config,\n",
    "        model_class=model_class,\n",
    "        model_init_params=model_init_params,\n",
    "        base_run_identifier=base_run_id, \n",
    "        reports_output_dir=reports_output_dir,\n",
    "        feature_models_output_dir=feature_models_output_dir,\n",
    "        random_state=random_state,\n",
    "        save_trained_features=save_models,\n",
    "        load_trained_features_if_exist=load_models,\n",
    "        single_split_test_size=single_split_test_size\n",
    "    )\n",
    "\n",
    "    if success:\n",
    "        print(f\"\\nExperiment '{base_run_id}' completed successfully.\")\n",
    "    else:\n",
    "        print(f\"\\nExperiment '{base_run_id}' encountered errors.\")\n",
    "\n",
    "    print(f\"\\n{model_name_script} with {feature_method_name} script finished for {dataset_config} dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4954a1",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Συνάρτηση `run_svm_experiment` που ενσωματώνει τη λογική εκτέλεσης του πειράματος."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110412ec",
   "metadata": {},
   "source": [
    "### 2.2. Εκτέλεση Πειράματος\n",
    "\n",
    "Το παρακάτω κελί θα εκτελέσει το πείραμα με τις ρυθμίσεις που ορίστηκαν παραπάνω."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30588a22",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Εισαγωγή στο κελί εκτέλεσης του πειράματος."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2365ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_svm_experiment(\n",
    "    dataset_config=DATASET_CONFIG,\n",
    "    feature_method=FEATURE_METHOD,\n",
    "    subset_percentage=SUBSET_PERCENTAGE,\n",
    "    n_splits_cv=N_SPLITS_CV,\n",
    "    random_state=RANDOM_STATE,\n",
    "    vectorizer_max_features=VECTORIZER_MAX_FEATURES,\n",
    "    single_split_test_size=SINGLE_SPLIT_TEST_SIZE,\n",
    "    save_models=SAVE_TRAINED_FEATURE_MODELS,\n",
    "    load_models=LOAD_TRAINED_FEATURE_MODELS_IF_EXIST\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1784037",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Εκτέλεση του πειράματος με τις καθορισμένες παραμέτρους."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc1524",
   "metadata": {},
   "source": [
    "## 3. Αποτελέσματα και Σχολιασμός\n",
    "\n",
    "Τα αναλυτικά αποτελέσματα (classification reports) για κάθε εκτέλεση αποθηκεύονται στον κατάλογο `outputs/[MODEL_FEATURE_CONFIG]/reports/`. \n",
    "\n",
    "Για παράδειγμα, αν εκτελέσατε SVM με BoW για το `subject`:\n",
    "`merosB1/i/outputs/SVM_BoW_subject/reports/`\n",
    "\n",
    "Τα αποτελέσματα που παρουσιάζονται στην επιστημονική αναφορά (`B1.md`) προέρχονται από εκτελέσεις αυτού του κώδικα."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7ed18b",
   "metadata": {},
   "source": [
    "**Επεξήγηση Κελιού:**\n",
    "Πληροφορίες για την εύρεση των αποτελεσμάτων και σύνδεση με την επιστημονική αναφορά."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
