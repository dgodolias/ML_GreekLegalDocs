{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbe6ddd6",
   "metadata": {},
   "source": [
    "## Τεχνικές Λεπτομέρειες SVM\n",
    "\n",
    "### Support Vector Machine (SVM) Παράμετροι:\n",
    "\n",
    "**Kernel**: `linear`\n",
    "- Χρησιμοποιείται γραμμικός πυρήνας που είναι αποδοτικός για high-dimensional δεδομένα κειμένου\n",
    "- Κατάλληλος όταν η διάσταση των χαρακτηριστικών είναι μεγάλη σε σχέση με τον αριθμό δειγμάτων\n",
    "\n",
    "**Probability**: `True`\n",
    "- Ενεργοποιεί τον υπολογισμό πιθανοτήτων κλάσεων μέσω Platt scaling\n",
    "- Χρήσιμο για την εξαγωγή confidence scores\n",
    "\n",
    "**Random State**: `42`\n",
    "- Εξασφαλίζει αναπαραγωγιμότητα των αποτελεσμάτων\n",
    "\n",
    "### Διαδικασία Ταξινόμησης:\n",
    "\n",
    "1. **Προεπεξεργασία**: Φόρτωση και καθαρισμός δεδομένων\n",
    "2. **Feature Extraction**: Μετατροπή κειμένου σε αριθμητικά χαρακτηριστικά\n",
    "3. **Train/Test Split**: Διαχωρισμός δεδομένων (80% εκπαίδευση, 20% αξιολόγηση)\n",
    "4. **Model Training**: Εκπαίδευση SVM στα χαρακτηριστικά εκπαίδευσης\n",
    "5. **Evaluation**: Αξιολόγηση με accuracy, precision, recall, f1-score\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898f4c7d",
   "metadata": {},
   "source": [
    "# Β1.i) Ταξινόμηση με SVM και Bag of Words / TF-IDF\n",
    "\n",
    "Αυτό το notebook εκτελεί ταξινόμηση με Support Vector Machine χρησιμοποιώντας δύο διαφορετικές μεθόδους εξαγωγής χαρακτηριστικών:\n",
    "1. Bag of Words (BoW) \n",
    "2. TF-IDF\n",
    "\n",
    "Το dataset που χρησιμοποιείται είναι το \"greek_legal_code\" από το Hugging Face Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "# Προσθήκη του parent directory στο path για να μπορούμε να εισάγουμε το utils\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "# Import utils functions\n",
    "try:\n",
    "    from utils import (\n",
    "        load_and_preprocess_data,\n",
    "        run_experiment,\n",
    "        script_execution_timer\n",
    "    )\n",
    "    print(\"Utils imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error importing utils: {e}\")\n",
    "    print(\"Continuing without utils functions...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9bd415",
   "metadata": {},
   "source": [
    "## Παραμετροποίηση\n",
    "\n",
    "Ορισμός των παραμέτρων για τα πειράματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e2d46ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset config: subject\n",
      "Subset percentage: 0.05\n",
      "Max features: 5000\n",
      "Test size: 0.2\n"
     ]
    }
   ],
   "source": [
    "# Κοινές παράμετροι\n",
    "DATASET_CONFIG = \"subject\"  # επιλογές: \"volume\", \"chapter\", \"subject\"\n",
    "SUBSET_PERCENTAGE = 0.05     # 1.0 για όλα τα δεδομένα, <1.0 για υποσύνολο\n",
    "N_SPLITS_CV = 1             # 1 για single split, >1 για K-Fold CV\n",
    "RANDOM_STATE = 42\n",
    "VECTORIZER_MAX_FEATURES = 5000\n",
    "SINGLE_SPLIT_TEST_SIZE = 0.2\n",
    "\n",
    "# Feature Engineering\n",
    "SAVE_TRAINED_FEATURE_MODELS = True\n",
    "LOAD_TRAINED_FEATURE_MODELS_IF_EXIST = True\n",
    "\n",
    "print(f\"Dataset config: {DATASET_CONFIG}\")\n",
    "print(f\"Subset percentage: {SUBSET_PERCENTAGE}\")\n",
    "print(f\"Max features: {VECTORIZER_MAX_FEATURES}\")\n",
    "print(f\"Test size: {SINGLE_SPLIT_TEST_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65648012",
   "metadata": {},
   "source": [
    "## Φόρτωση και Προεπεξεργασία Δεδομένων\n",
    "\n",
    "Φόρτωση του dataset και προετοιμασία για τα πειράματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1290188c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Φόρτωση δεδομένων...\n",
      "Φόρτωση dataset χωρίς utils...\n",
      "Error loading dataset: name 'load_dataset' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Φόρτωση των δεδομένων\n",
    "print(\"Φόρτωση δεδομένων...\")\n",
    "\n",
    "# Αν υπάρχει η συνάρτηση utils, χρησιμοποιούμε αυτή\n",
    "if 'load_and_preprocess_data' in globals():\n",
    "    all_texts, all_labels, label_names, num_classes = load_and_preprocess_data(\n",
    "        DATASET_CONFIG, SUBSET_PERCENTAGE, RANDOM_STATE\n",
    "    )\n",
    "else:\n",
    "    # Εναλλακτική φόρτωση χωρίς utils\n",
    "    print(\"Φόρτωση dataset χωρίς utils...\")\n",
    "    try:\n",
    "        ds = load_dataset(\"AI-team-UoA/greek_legal_code\", DATASET_CONFIG, trust_remote_code=True)\n",
    "        dataset_split = ds['train']\n",
    "        all_texts = dataset_split['text']\n",
    "        all_labels = np.array(dataset_split['label'])\n",
    "        label_names = dataset_split.features['label'].names\n",
    "        num_classes = len(label_names)\n",
    "        print(f\"Dataset loaded successfully. Samples: {len(all_texts)}, Classes: {num_classes}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset: {e}\")\n",
    "        all_texts, all_labels, label_names, num_classes = None, None, None, None\n",
    "\n",
    "if all_texts is not None:\n",
    "    print(f\"Συνολικά samples: {len(all_texts)}\")\n",
    "    print(f\"Αριθμός κλάσεων: {num_classes}\")\n",
    "    print(f\"Ονόματα κλάσεων: {label_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ec3fe8",
   "metadata": {},
   "source": [
    "## 1. SVM με Bag of Words (BoW)\n",
    "\n",
    "### Τεχνικά Χαρακτηριστικά Bag of Words:\n",
    "\n",
    "**Bag of Words (BoW)** είναι μια μέθοδος εξαγωγής χαρακτηριστικών από κείμενο που:\n",
    "\n",
    "- **Αναπαράσταση**: Μετατρέπει κάθε κείμενο σε διάνυσμα με διάσταση ίση με το μέγεθος του λεξιλογίου\n",
    "- **Συχνότητα**: Κάθε στοιχείο του διανύσματος αντιπροσωπεύει τη συχνότητα εμφάνισης μιας λέξης\n",
    "- **Απλότητα**: Αγνοεί τη σειρά των λέξεων και τη γραμματική δομή\n",
    "- **Αραιότητα**: Παράγει αραιά διανύσματα (πολλά μηδενικά στοιχεία)\n",
    "- **Max Features**: Χρησιμοποιούμε τις 5000 πιο συχνές λέξεις για να περιορίσουμε τη διάσταση\n",
    "\n",
    "**Πλεονεκτήματα:**\n",
    "- Απλή υλοποίηση και γρήγορη εκτέλεση\n",
    "- Καλή απόδοση σε πολλές εφαρμογές ταξινόμησης κειμένου\n",
    "- Δεν απαιτεί προεκπαίδευση\n",
    "\n",
    "**Μειονεκτήματα:**\n",
    "- Δεν καταγράφει τη σημασιολογική σχέση μεταξύ λέξεων\n",
    "- Υψηλή διάσταση μπορεί να οδηγήσει σε curse of dimensionality\n",
    "\n",
    "Εκτέλεση ταξινόμησης με SVM χρησιμοποιώντας Bag of Words για την εξαγωγή χαρακτηριστικών."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e49c5d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Δεν μπορεί να εκτελεστεί το πείραμα - δεν φορτώθηκαν δεδομένα\n"
     ]
    }
   ],
   "source": [
    "def run_svm_bow_experiment():\n",
    "    \"\"\"Εκτέλεση SVM με Bag of Words\"\"\"\n",
    "    \n",
    "    print(\"=== Ξεκινάει το πείραμα SVM με Bag of Words ===\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Παραμετροποίηση για BoW\n",
    "    model_name_script = \"SVM\"\n",
    "    feature_method_name = \"BoW\"\n",
    "    base_run_id = f\"{model_name_script}_{feature_method_name}_{DATASET_CONFIG}\"\n",
    "    \n",
    "    # Ρύθμιση feature extraction\n",
    "    feature_config = {\n",
    "        'method': 'sklearn_vectorizer',\n",
    "        'class': CountVectorizer,\n",
    "        'params': {'max_features': VECTORIZER_MAX_FEATURES}\n",
    "    }\n",
    "    \n",
    "    # Ρύθμιση μοντέλου\n",
    "    model_class = SVC\n",
    "    model_init_params = {'kernel': 'linear', 'probability': True, 'random_state': RANDOM_STATE}\n",
    "    \n",
    "    # Δημιουργία output directories\n",
    "    script_dir = os.path.dirname(os.path.abspath(''))\n",
    "    experiment_output_base_dir = os.path.join(script_dir, \"outputs\", base_run_id)\n",
    "    reports_output_dir = os.path.join(experiment_output_base_dir, \"reports\")\n",
    "    feature_models_output_dir = os.path.join(experiment_output_base_dir, \"feature_models\")\n",
    "    \n",
    "    # Δημιουργία directories αν δεν υπάρχουν\n",
    "    os.makedirs(reports_output_dir, exist_ok=True)\n",
    "    os.makedirs(feature_models_output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Output directory: {experiment_output_base_dir}\")\n",
    "    \n",
    "    # Αν υπάρχει η run_experiment από utils, χρησιμοποιούμε αυτή\n",
    "    if 'run_experiment' in globals() and all_texts is not None:\n",
    "        try:\n",
    "            run_experiment(\n",
    "                all_texts=all_texts,\n",
    "                all_labels=all_labels,\n",
    "                label_names=label_names,\n",
    "                num_classes=num_classes,\n",
    "                feature_config=feature_config,\n",
    "                model_class=model_class,\n",
    "                model_init_params=model_init_params,\n",
    "                n_splits_cv=N_SPLITS_CV,\n",
    "                single_split_test_size=SINGLE_SPLIT_TEST_SIZE,\n",
    "                random_state=RANDOM_STATE,\n",
    "                reports_output_dir=reports_output_dir,\n",
    "                feature_models_output_dir=feature_models_output_dir,\n",
    "                save_trained_feature_models=SAVE_TRAINED_FEATURE_MODELS,\n",
    "                load_trained_feature_models_if_exist=LOAD_TRAINED_FEATURE_MODELS_IF_EXIST\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error in run_experiment: {e}\")\n",
    "            print(\"Εκτέλεση απλουστευμένου πειράματος...\")\n",
    "            run_simple_experiment(feature_config, model_class, model_init_params, \"BoW\")\n",
    "    else:\n",
    "        print(\"Εκτέλεση απλουστευμένου πειράματος...\")\n",
    "        run_simple_experiment(feature_config, model_class, model_init_params, \"BoW\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"=== Ολοκληρώθηκε το πείραμα BoW σε {end_time - start_time:.2f} δευτερόλεπτα ===\")\n",
    "\n",
    "# Εκτέλεση πειράματος BoW\n",
    "if all_texts is not None:\n",
    "    run_svm_bow_experiment()\n",
    "else:\n",
    "    print(\"Δεν μπορεί να εκτελεστεί το πείραμα - δεν φορτώθηκαν δεδομένα\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6786f50f",
   "metadata": {},
   "source": [
    "## 2. SVM με TF-IDF\n",
    "\n",
    "### Τεχνικά Χαρακτηριστικά TF-IDF:\n",
    "\n",
    "**TF-IDF (Term Frequency - Inverse Document Frequency)** είναι μια βελτιωμένη έκδοση του BoW που:\n",
    "\n",
    "**Term Frequency (TF):**\n",
    "- Μετρά τη συχνότητα μιας λέξης σε ένα έγγραφο\n",
    "- TF(t,d) = (αριθμός εμφανίσεων του όρου t στο έγγραφο d) / (συνολικός αριθμός όρων στο έγγραφο d)\n",
    "\n",
    "**Inverse Document Frequency (IDF):**\n",
    "- Μετρά τη σπανιότητα μιας λέξης σε όλη τη συλλογή εγγράφων\n",
    "- IDF(t,D) = log(N / |{d ∈ D : t ∈ d}|)\n",
    "- Όπου N = συνολικός αριθμός εγγράφων\n",
    "\n",
    "**TF-IDF Score:**\n",
    "- TF-IDF(t,d,D) = TF(t,d) × IDF(t,D)\n",
    "- Δίνει μεγαλύτερο βάρος σε λέξεις που είναι συχνές σε ένα έγγραφο αλλά σπάνιες στη συλλογή\n",
    "\n",
    "**Πλεονεκτήματα:**\n",
    "- Μειώνει τη σημασία των κοινών λέξεων (stop words)\n",
    "- Αναδεικνύει τις χαρακτηριστικές λέξεις κάθε εγγράφου\n",
    "- Καλύτερη αναπαράσταση της σημασίας των λέξεων\n",
    "\n",
    "**Μειονεκτήματα:**\n",
    "- Πιο υπολογιστικά πολύπλοκο από το BoW\n",
    "- Εξακολουθεί να αγνοεί τη σειρά των λέξεων\n",
    "\n",
    "**Παράμετροι sklearn.TfidfVectorizer:**\n",
    "- `max_features=5000`: Χρήση των 5000 πιο σημαντικών όρων\n",
    "- `smooth_idf=True`: Εξομάλυνση IDF για αποφυγή διαίρεσης με μηδέν\n",
    "- `norm='l2'`: L2 κανονικοποίηση των διανυσμάτων\n",
    "\n",
    "Εκτέλεση ταξινόμησης με SVM χρησιμοποιώντας TF-IDF για την εξαγωγή χαρακτηριστικών."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44900768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Δεν μπορεί να εκτελεστεί το πείραμα - δεν φορτώθηκαν δεδομένα\n"
     ]
    }
   ],
   "source": [
    "def run_svm_tfidf_experiment():\n",
    "    \"\"\"Εκτέλεση SVM με TF-IDF\"\"\"\n",
    "    \n",
    "    print(\"=== Ξεκινάει το πείραμα SVM με TF-IDF ===\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Παραμετροποίηση για TF-IDF\n",
    "    model_name_script = \"SVM\"\n",
    "    feature_method_name = \"TF-IDF\"\n",
    "    base_run_id = f\"{model_name_script}_{feature_method_name.replace('-', '')}_{DATASET_CONFIG}\"\n",
    "    \n",
    "    # Ρύθμιση feature extraction\n",
    "    feature_config = {\n",
    "        'method': 'sklearn_vectorizer',\n",
    "        'class': TfidfVectorizer,\n",
    "        'params': {'max_features': VECTORIZER_MAX_FEATURES}\n",
    "    }\n",
    "    \n",
    "    # Ρύθμιση μοντέλου\n",
    "    model_class = SVC\n",
    "    model_init_params = {'kernel': 'linear', 'probability': True, 'random_state': RANDOM_STATE}\n",
    "    \n",
    "    # Δημιουργία output directories\n",
    "    script_dir = os.path.dirname(os.path.abspath(''))\n",
    "    experiment_output_base_dir = os.path.join(script_dir, \"outputs\", base_run_id)\n",
    "    reports_output_dir = os.path.join(experiment_output_base_dir, \"reports\")\n",
    "    feature_models_output_dir = os.path.join(experiment_output_base_dir, \"feature_models\")\n",
    "    \n",
    "    # Δημιουργία directories αν δεν υπάρχουν\n",
    "    os.makedirs(reports_output_dir, exist_ok=True)\n",
    "    os.makedirs(feature_models_output_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Output directory: {experiment_output_base_dir}\")\n",
    "    \n",
    "    # Αν υπάρχει η run_experiment από utils, χρησιμοποιούμε αυτή\n",
    "    if 'run_experiment' in globals() and all_texts is not None:\n",
    "        try:\n",
    "            run_experiment(\n",
    "                all_texts=all_texts,\n",
    "                all_labels=all_labels,\n",
    "                label_names=label_names,\n",
    "                num_classes=num_classes,\n",
    "                feature_config=feature_config,\n",
    "                model_class=model_class,\n",
    "                model_init_params=model_init_params,\n",
    "                n_splits_cv=N_SPLITS_CV,\n",
    "                single_split_test_size=SINGLE_SPLIT_TEST_SIZE,\n",
    "                random_state=RANDOM_STATE,\n",
    "                reports_output_dir=reports_output_dir,\n",
    "                feature_models_output_dir=feature_models_output_dir,\n",
    "                save_trained_feature_models=SAVE_TRAINED_FEATURE_MODELS,\n",
    "                load_trained_feature_models_if_exist=LOAD_TRAINED_FEATURE_MODELS_IF_EXIST\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error in run_experiment: {e}\")\n",
    "            print(\"Εκτέλεση απλουστευμένου πειράματος...\")\n",
    "            run_simple_experiment(feature_config, model_class, model_init_params, \"TF-IDF\")\n",
    "    else:\n",
    "        print(\"Εκτέλεση απλουστευμένου πειράματος...\")\n",
    "        run_simple_experiment(feature_config, model_class, model_init_params, \"TF-IDF\")\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(f\"=== Ολοκληρώθηκε το πείραμα TF-IDF σε {end_time - start_time:.2f} δευτερόλεπτα ===\")\n",
    "\n",
    "# Εκτέλεση πειράματος TF-IDF\n",
    "if all_texts is not None:\n",
    "    run_svm_tfidf_experiment()\n",
    "else:\n",
    "    print(\"Δεν μπορεί να εκτελεστεί το πείραμα - δεν φορτώθηκαν δεδομένα\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3d7f13",
   "metadata": {},
   "source": [
    "## Απλουστευμένη Εκτέλεση Πειραμάτων\n",
    "\n",
    "Στην περίπτωση που δεν είναι διαθέσιμες οι συναρτήσεις utils, εκτελείται μια απλουστευμένη έκδοση."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019858f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simple_experiment(feature_config, model_class, model_init_params, method_name):\n",
    "    \"\"\"Απλουστευμένη εκτέλεση πειράματος χωρίς utils\"\"\"\n",
    "    \n",
    "    if all_texts is None or all_labels is None:\n",
    "        print(\"Δεν είναι διαθέσιμα δεδομένα για το πείραμα\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Εκτέλεση απλουστευμένου πειράματος για {method_name}\")\n",
    "    \n",
    "    # Διαχωρισμός σε training/testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        all_texts, all_labels, \n",
    "        test_size=SINGLE_SPLIT_TEST_SIZE, \n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=all_labels\n",
    "    )\n",
    "    \n",
    "    print(f\"Training samples: {len(X_train)}\")\n",
    "    print(f\"Testing samples: {len(X_test)}\")\n",
    "    \n",
    "    # Feature extraction\n",
    "    vectorizer_class = feature_config['class']\n",
    "    vectorizer_params = feature_config['params']\n",
    "    vectorizer = vectorizer_class(**vectorizer_params)\n",
    "    \n",
    "    print(f\"Εξαγωγή χαρακτηριστικών με {method_name}...\")\n",
    "    X_train_features = vectorizer.fit_transform(X_train)\n",
    "    X_test_features = vectorizer.transform(X_test)\n",
    "    \n",
    "    print(f\"Feature shape: {X_train_features.shape}\")\n",
    "    \n",
    "    # Model training\n",
    "    print(f\"Εκπαίδευση SVM μοντέλου...\")\n",
    "    model = model_class(**model_init_params)\n",
    "    model.fit(X_train_features, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    print(\"Υπολογισμός προβλέψεων...\")\n",
    "    y_pred = model.predict(X_test_features)\n",
    "    \n",
    "    # Evaluation\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred, target_names=label_names)\n",
    "    \n",
    "    print(f\"\\n=== Αποτελέσματα για {method_name} ===\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'classification_report': report,\n",
    "        'method': method_name\n",
    "    }\n",
    "\n",
    "print(\"Συνάρτηση απλουστευμένου πειράματος ορίστηκε επιτυχώς\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0e64bc",
   "metadata": {},
   "source": [
    "## Εντολές Εκτέλεσης\n",
    "\n",
    "Για να εκτελέσετε τα πειράματα χωριστά μέσω terminal, χρησιμοποιήστε:\n",
    "\n",
    "```bash\n",
    "# Για SVM με Bag of Words\n",
    "python merosB1/i/main_SVM_BoW.py\n",
    "\n",
    "# Για SVM με TF-IDF\n",
    "python merosB1/i/main_SVM_TFIDF.py\n",
    "```\n",
    "\n",
    "Τα αποτελέσματα θα αποθηκευτούν στους αντίστοιχους φακέλους `outputs/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d99e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Εναλλακτική εκτέλεση με υποσύνολο δεδομένων για γρήγορη δοκιμή\n",
    "print(\"\\n=== Γρήγορη Δοκιμή με Υποσύνολο Δεδομένων ===\")\n",
    "\n",
    "if all_texts is not None and len(all_texts) > 1000:\n",
    "    # Χρήση 10% των δεδομένων για γρήγορη δοκιμή\n",
    "    subset_size = int(len(all_texts) * 0.1)\n",
    "    indices = np.random.choice(len(all_texts), subset_size, replace=False)\n",
    "    \n",
    "    subset_texts = [all_texts[i] for i in indices]\n",
    "    subset_labels = all_labels[indices]\n",
    "    \n",
    "    print(f\"Χρήση {subset_size} samples από {len(all_texts)} για γρήγορη δοκιμή\")\n",
    "    \n",
    "    # Δοκιμή με BoW\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        subset_texts, subset_labels, test_size=0.2, random_state=42, stratify=subset_labels\n",
    "    )\n",
    "    \n",
    "    # BoW\n",
    "    bow_vectorizer = CountVectorizer(max_features=1000)\n",
    "    X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "    X_test_bow = bow_vectorizer.transform(X_test)\n",
    "    \n",
    "    svm_bow = SVC(kernel='linear', random_state=42)\n",
    "    svm_bow.fit(X_train_bow, y_train)\n",
    "    y_pred_bow = svm_bow.predict(X_test_bow)\n",
    "    \n",
    "    print(f\"\\nBoW Accuracy: {accuracy_score(y_test, y_pred_bow):.4f}\")\n",
    "    \n",
    "    # TF-IDF\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "    \n",
    "    svm_tfidf = SVC(kernel='linear', random_state=42)\n",
    "    svm_tfidf.fit(X_train_tfidf, y_train)\n",
    "    y_pred_tfidf = svm_tfidf.predict(X_test_tfidf)\n",
    "    \n",
    "    print(f\"TF-IDF Accuracy: {accuracy_score(y_test, y_pred_tfidf):.4f}\")\n",
    "    \n",
    "    print(\"\\nΣύγκριση αποτελεσμάτων:\")\n",
    "    print(f\"TF-IDF vs BoW: {'+' if accuracy_score(y_test, y_pred_tfidf) > accuracy_score(y_test, y_pred_bow) else '-'}{abs(accuracy_score(y_test, y_pred_tfidf) - accuracy_score(y_test, y_pred_bow)):.4f}\")\n",
    "else:\n",
    "    print(\"Δεν υπάρχουν αρκετά δεδομένα για δοκιμή\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000ba3f8",
   "metadata": {},
   "source": [
    "## Αναμενόμενα Αποτελέσματα βάσει των προηγούμενων εκτελέσεων\n",
    "\n",
    "Βάσει των αρχείων στο `outputsfinal/i/`, αναμένουμε:\n",
    "\n",
    "- **TF-IDF εμφανίζει γενικά καλύτερη απόδοση** από το BoW\n",
    "- **Καλύτερα αποτελέσματα** σε `subject` και `chapter` configurations\n",
    "- **Χαμηλότερη απόδοση** σε `volume` configuration (περισσότερες κλάσεις)\n",
    "- **Επάρκεια 5000 features** για ικανοποιητική απόδοση\n",
    "\n",
    "Τα πειράματα σας θα επιβεβαιώσουν ή θα ανατρέψουν αυτές τις προσδοκίες!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6461cc62",
   "metadata": {},
   "source": [
    "## Σύγκριση των Μεθόδων\n",
    "\n",
    "### Bag of Words vs TF-IDF\n",
    "\n",
    "| Κριτήριο | Bag of Words | TF-IDF |\n",
    "|----------|--------------|--------|\n",
    "| **Υπολογιστική Πολυπλοκότητα** | Χαμηλή | Μέτρια |\n",
    "| **Χειρισμός Κοινών Λέξεων** | Δεν φιλτράρει | Μειώνει τη σημασία τους |\n",
    "| **Αναπαράσταση Σημασίας** | Απλή συχνότητα | Σταθμισμένη σημασία |\n",
    "| **Μνήμη** | Χαμηλές απαιτήσεις | Μεσαίες απαιτήσεις |\n",
    "| **Ευκολία Ερμηνείας** | Πολύ εύκολη | Μέτρια |\n",
    "| **Απόδοση σε Μεγάλα Κείμενα** | Καλή | Πολύ καλή |\n",
    "\n",
    "### Αναμενόμενα Αποτελέσματα:\n",
    "\n",
    "**TF-IDF αναμένεται να υπερτερεί** γιατί:\n",
    "- Μειώνει τη σημασία των stop words και κοινών λέξεων\n",
    "- Αναδεικνύει χαρακτηριστικούς όρους κάθε νομικής κατηγορίας\n",
    "- Καλύτερη αντιμετώπιση του vocabulary mismatch\n",
    "\n",
    "**BoW μπορεί να είναι ανταγωνιστικό** σε περιπτώσεις:\n",
    "- Όπου η συχνότητα εμφάνισης είναι σημαντική\n",
    "- Μικρότερα datasets\n",
    "- Όταν χρειαζόμαστε ταχύτητα\n",
    "\n",
    "### Παράγονες που Επηρεάζουν την Απόδοση:\n",
    "\n",
    "1. **Ποιότητα Dataset**: Καθαρότητα και ομοιογένεια των νομικών κειμένων\n",
    "2. **Μέγεθος Λεξιλογίου**: 5000 max_features μπορεί να περιορίζει την έκφραση\n",
    "3. **Κατανομή Κλάσεων**: Ισορροπία μεταξύ των νομικών κατηγοριών\n",
    "4. **Γλωσσικά Χαρακτηριστικά**: Πλούσια ελληνική ορολογία του νομικού τομέα\n",
    "\n",
    "---\n",
    "\n",
    "## Σύνοψη Αποτελεσμάτων\n",
    "\n",
    "Τα αποτελέσματα των πειραμάτων θα αποθηκευτούν στον φάκελο `outputs/` και θα περιλαμβάνουν:\n",
    "\n",
    "1. **SVM με Bag of Words**: Classification reports και μετρικές απόδοσης\n",
    "2. **SVM με TF-IDF**: Classification reports και μετρικές απόδοσης\n",
    "\n",
    "Κάθε πείραμα παράγει:\n",
    "- Classification report (σε μορφή JSON και text)\n",
    "- Αποθηκευμένα μοντέλα feature extraction (εάν ενεργοποιηθεί)\n",
    "- Λεπτομερή logs της εκτέλεσης\n",
    "\n",
    "Τα αποτελέσματα μπορούν να συγκριθούν για να αξιολογηθεί η απόδοση των δύο μεθόδων εξαγωγής χαρακτηριστικών."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdfbf97",
   "metadata": {},
   "source": [
    "## Πρακτικές Συμβουλές για Βελτίωση\n",
    "\n",
    "### Προεπεξεργασία Κειμένου:\n",
    "- **Κανονικοποίηση**: Μετατροπή σε πεζά γράμματα\n",
    "- **Stemming/Lemmatization**: Μείωση λέξεων στη ρίζα τους\n",
    "- **Stop Words Removal**: Αφαίρεση κοινών λέξεων (άρθρα, σύνδεσμοι)\n",
    "- **N-grams**: Χρήση bigrams ή trigrams για σύλληψη φράσεων\n",
    "\n",
    "### Βελτιστοποίηση Παραμέτρων:\n",
    "- **max_features**: Δοκιμή διαφορετικών τιμών (1000, 5000, 10000)\n",
    "- **min_df/max_df**: Φιλτράρισμα σπάνιων ή πολύ κοινών όρων\n",
    "- **SVM C parameter**: Ρύθμιση regularization\n",
    "- **Cross-validation**: Χρήση K-fold για πιο αξιόπιστα αποτελέσματα\n",
    "\n",
    "### Αξιολόγηση Αποτελεσμάτων:\n",
    "- **Confusion Matrix**: Ανάλυση λαθών ανά κατηγορία\n",
    "- **Feature Importance**: Εύρεση των πιο σημαντικών όρων\n",
    "- **Learning Curves**: Έλεγχος για overfitting/underfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
