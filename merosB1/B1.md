# Επιστημονική Αναφορά: Μέρος Β1 - Ταξινόμηση Ελληνικών Νομικών Εγγράφων

**Φοιτητής/ΑΜ:** Δημοσθένης Παναγιώτης Γκοντόλιας/3220031
**Ημερομηνία:** 24 Μαΐου 2025

## 1. Εισαγωγή

Η παρούσα αναφορά συνοψίζει την ταξινόμηση ελληνικών νομικών εγγράφων (~47.000) από τον "Ελληνικό Νομικό Κώδικα" για τις ετικέτες `volume`, `chapter`, και `subject`. Χρησιμοποιήθηκαν μοντέλα Λογιστικής Παλινδρόμησης (LogReg), XGBoost, και Support Vector Machines (SVM) με διανυσματικές αναπαραστάσεις Word2Vec, Bag-of-Words (BoW), και TF-IDF. Στους φακέλους παραδίδονται και from-scratch υλοποιήσεις(SVM_MY_IMPLEMENTATION.py, LR_MY_IMPLEMENTATION.py, XGB_MY_IMPLEMENTATION.py), οι οποίες δεν χρησιμοποιήθηκαν λόγω υπολογιστικών περιορισμών, και έπειτα απο σχετική συζήτηση με τους υπεύθυνους. Η αξιολόγηση έγινε με Accuracy, Precision, Recall και F1-score. Δεδομένης της σημαντικής ανισορροπίας των κλάσεων, όπως φαίνεται και από μετρικές όπως ο Λόγος Ανισορροπίας (Imbalance Ratio - IR), ο Συντελεστής Μεταβλητότητας (Coefficient of Variation - CV) και η Εντροπία της κατανομής των κλάσεων (Entropy) που υπολογίστηκαν (βλ. `check_class_balance.py`), δίνεται έμφαση στο F1-score έναντι του Accuracy για την αξιολόγηση των μοντέλων.

## 2. Μεθοδολογία

**Προεπεξεργασία:** Φιλτράρισμα κλάσεων <2 δειγμάτων, αριθμητική κωδικοποίηση ετικετών.
**Διαχωρισμός Δεδομένων:** 80%/20% train/test split λόγω υπολογιστικών περιορισμών(απουσία validation set για βελτιστοποίηση υπερπαραμέτρων, λόγω περιορισμών GP). Για την ετικέτα `volume` έγινε 5-fold stratified CV για όλα τα μοντέλα (LogReg, XGBoost, SVM). 
**Χαρακτηριστικά:** Word2Vec (CBOW, vector_size=100, window=5, min_count=2, epochs=10) για τη δημιουργία μέσου όρου διανυσμάτων λέξεων ανά έγγραφο.
**Μοντέλα:**
*   LogReg (`solver='liblinear'`, `max_iter=1000`).
*   XGBoost (`n_estimators=100`, `learning_rate=0.1`, `max_depth=3`, `eval_metric='mlogloss'`).
*   SVM (τυπικά `C=1.0`).
Η βελτιστοποίηση υπερπαραμέτρων δεν ήταν συστηματική.
**Αξιολόγηση:** Μετρικές `weighted average` για πολλαπλές κλάσεις. Σύγκριση με theoretical random baseline classifier (1/Ν κλάσεων).

## 3. Αποτελέσματα (Σταθμισμένο F1-score / Ορθότητα)

| Στόχος    | Κλάσεις | Τυχ. Βάση | LogReg + W2V (Single) | LogReg + W2V (5-CV) | XGBoost + W2V (Single) | XGBoost + W2V (5-CV) | SVM + BoW (Single) | SVM + BoW (5-CV) | SVM + TF-IDF (Single) | SVM + TF-IDF (5-CV) |
| :-------- | :------- | :--------- | :-------------------- | :-------------------- | :--------------------- | :------------------- | :----------------- | :--------------- | :-------------------- | :------------------ |
| `volume`  | 47       | ~0.021     | -                     | 0.461 / 0.478         | -                      | 0.348 / 0.372        | -                  | 0.643 / 0.643    | -                     | 0.756 / 0.758       |
| `chapter` | 389      | ~0.0026    | 0.370 / 0.4000        | -                     | 0.260 / 0.2800         | -                    | 0.756 / 0.758     | -                | 0.640 / 0.6600        | -                   |
| `subject` | 2285     | ~0.0004    | 0.270 / 0.3000        | -                     | 0.190 / 0.2100         | -                    | 0.360 / 0.3500     | -                | 0.220 / 0.2400        | -                   |


## 4. Συζήτηση και Συμπεράσματα

Όλα τα μοντέλα ξεπέρασαν σημαντικά τον theoretical random baseline classifier.

*   **Απόδοση:** Τα μοντέλα παρουσιάζουν διαφορετική συμπεριφορά ανάλογα με την ετικέτα και την τεχνική feature extraction:
    - **Volume (47 κλάσεις):** Το **SVM με TF-IDF** επιτυγχάνει την καλύτερη απόδοση (F1: 0.756), ακολουθούμενο από το SVM με BoW (F1: 0.643). Το LogReg με Word2Vec έχει μέτρια απόδοση (F1: 0.461), ενώ το XGBoost με Word2Vec υστερεί (F1: 0.348).
    - **Chapter (389 κλάσεις):** Και εδώ το **SVM με BoW** υπερτερεί σημαντικά (F1: 0.756), ενώ το SVM με TF-IDF ακολουθεί (F1: 0.640). Τα Word2Vec μοντέλα (LogReg: 0.370, XGBoost: 0.260) έχουν χαμηλότερη απόδοση.
    - **Subject (2285 κλάσεις):** Για την πιο δύσκολη κατηγορία με τις περισσότερες κλάσεις, το **SVM με BoW** παραμένει το καλύτερο (F1: 0.360), ακολουθούμενο από LogReg με Word2Vec (F1: 0.270). Το SVM με TF-IDF και XGBoost έχουν τη χειρότερη απόδοση (F1: 0.220 και 0.190 αντίστοιχα).

*   **Παρατηρήσεις ανά μέθοδο:**
    - **SVM:** Αναδεικνύεται ως η πιο αποτελεσματική μέθοδος, με το BoW να είναι ιδιαίτερα αποτελεσματικό σε όλες τις κατηγορίες, ενώ το TF-IDF υπερτερεί στον volume αλλά υποδοσεί στις άλλες κατηγορίες.
    - **Word2Vec:** Παρουσιάζει μέτρια απόδοση σε όλες τις κατηγορίες, με τη LogReg να υπερτερεί του XGBoost. Η περιορισμένη απόδοση μπορεί να οφείλεται στην απλούστευση που επιφέρει η μέση τιμή των word embeddings ανά έγγραφο.
    - **Επίδραση πολυπλοκότητας:** Καθώς αυξάνει ο αριθμός των κλάσεων (47→389→2285), η απόδοση όλων των μοντέλων μειώνεται, όπως αναμενόταν.

*   **Αξιολόγηση:** Η χρήση 5-fold Cross-Validation για την ετικέτα `volume` παρείχε μια πιο στιβαρή εκτίμηση της απόδοσης των μοντέλων σε σύγκριση με το απλό train/test split που χρησιμοποιήθηκε για τις `chapter` και `subject` λόγω υπολογιστικών περιορισμών. Η στρωματοποίηση (stratification) κατά τον διαχωρισμό των δεδομένων και η χρήση `weighted average` για τις μετρικές ήταν σημαντικές για την αντιμετώπιση της ανισορροπίας των κλάσεων.

*   **Περιορισμοί:** Οι χρησιμοποιηθείσες Word2Vec αναπαραστάσεις, αν και αποτελεσματικές σε κάποιο βαθμό, ενδέχεται να μην συλλαμβάνουν πλήρως την πλούσια σημασιολογία των νομικών κειμένων όταν συντίθενται ως μέση τιμή. Επιπλέον, η έλλειψη συστηματικής βελτιστοποίησης υπερπαραμέτρων και η περιορισμένη χρήση CV για τις ετικέτες `chapter` και `subject` αποτελούν περιορισμούς της τρέχουσας μελέτης.

**Συμπέρασμα:** Η παρούσα μελέτη καταδεικνύει τη βιωσιμότητα της χρήσης μοντέλων μηχανικής μάθησης για την ταξινόμηση ελληνικών νομικών εγγράφων. Τα **SVM μοντέλα αναδεικνύονται ως τα πιο αποτελεσματικά**, με την τεχνική BoW να επιτυγχάνει συνεπώς υψηλή απόδοση σε όλες τις κατηγορίες, ενώ το TF-IDF εξειδικεύεται στην κατηγορία volume. Η σχετικά χαμηλή απόδοση των Word2Vec μοντέλων υποδηλώνει ότι η απλή μέση τιμή των embeddings ενδεχομένως δεν αξιοποιεί πλήρως τη σημασιολογική πληροφορία. Παρά τους περιορισμούς, όλα τα μοντέλα ξεπερνούν σημαντικά τον theoretical random baseline classifier, αποδεικνύοντας ότι μαθαίνουν ουσιαστικά πρότυπα από τα δεδομένα. Η χρήση πιο εξελιγμένων τεχνικών αναπαράστασης κειμένου (π.χ. contextualized embeddings) και η εκτεταμένη βελτιστοποίηση υπερπαραμέτρων αναμένεται να βελτιώσουν περαιτέρω την απόδοση.
