# Επιστημονική Αναφορά: Μέρος Β1 - Ταξινόμηση Ελληνικών Νομικών Εγγράφων

**Φοιτητής/ΑΜ:** Δημοσθένης Παναγιώτης Γκοντόλιας/3220031
**Ημερομηνία:** 24 Μαΐου 2025

## 1. Εισαγωγή

Η παρούσα αναφορά συνοψίζει την ταξινόμηση ελληνικών νομικών εγγράφων (~47.000) από τον "Ελληνικό Νομικό Κώδικα" για τις ετικέτες `volume`, `chapter`, και `subject`. Χρησιμοποιήθηκαν μοντέλα Λογιστικής Παλινδρόμησης (LogReg), XGBoost, και Support Vector Machines (SVM) με διανυσματικές αναπαραστάσεις Word2Vec, Bag-of-Words (BoW), και TF-IDF. Στους φακέλους παραδίδονται και from-scratch υλοποιήσεις(SVM_MY_IMPLEMENTATION.py, LR_MY_IMPLEMENTATION.py, XGB_MY_IMPLEMENTATION.py), οι οποίες δεν χρησιμοποιήθηκαν λόγω υπολογιστικών περιορισμών, και έπειτα απο σχετική συζήτηση με τους υπεύθυνους. Η αξιολόγηση έγινε με Accuracy, Precision, Recall και F1-score. Δεδομένης της σημαντικής ανισορροπίας των κλάσεων, όπως φαίνεται και από μετρικές όπως ο Λόγος Ανισορροπίας (Imbalance Ratio - IR), ο Συντελεστής Μεταβλητότητας (Coefficient of Variation - CV) και η Εντροπία της κατανομής των κλάσεων (Entropy) που υπολογίστηκαν (βλ. `check_class_balance.py`), δίνεται έμφαση στο F1-score έναντι του Accuracy για την αξιολόγηση των μοντέλων.

## 2. Μεθοδολογία

**Προεπεξεργασία:** Φιλτράρισμα κλάσεων <2 δειγμάτων, αριθμητική κωδικοποίηση ετικετών.
**Διαχωρισμός Δεδομένων:** 80%/20% train/test split λόγω υπολογιστικών περιορισμών(απουσία validation set για βελτιστοποίηση υπερπαραμέτρων, λόγω περιορισμών GP). Για την ετικέτα `volume` έγινε 5-fold stratified CV για όλα τα μοντέλα (LogReg, XGBoost, SVM). 
**Χαρακτηριστικά:** Word2Vec (CBOW, vector_size=100, window=5, min_count=2, epochs=10) για τη δημιουργία μέσου όρου διανυσμάτων λέξεων ανά έγγραφο.
**Μοντέλα:**
*   LogReg (`solver='liblinear'`, `max_iter=1000`).
*   XGBoost (`n_estimators=100`, `learning_rate=0.1`, `max_depth=3`, `eval_metric='mlogloss'`).
*   SVM (τυπικά `C=1.0`).
Η βελτιστοποίηση υπερπαραμέτρων δεν ήταν συστηματική.
**Αξιολόγηση:** Μετρικές `weighted average` για πολλαπλές κλάσεις. Σύγκριση με τυχαία γραμμή βάσης (1/Ν κλάσεων).

## 3. Αποτελέσματα (Σταθμισμένο F1-score / Ορθότητα)

| Στόχος    | Κλάσεις | Τυχ. Βάση | LogReg + W2V (Single) | LogReg + W2V (5-CV) | XGBoost + W2V (Single) | XGBoost + W2V (5-CV) | SVM + BoW (Single) | SVM + BoW (5-CV) | SVM + TF-IDF (Single) | SVM + TF-IDF (5-CV) |
| :-------- | :------- | :--------- | :-------------------- | :-------------------- | :--------------------- | :------------------- | :----------------- | :--------------- | :-------------------- | :------------------ |
| `volume`  | 47       | ~0.021     | -                     | 0.461 / (Μ/Δ)         | -                      | 0.348 / (Μ/Δ)        | -                  | 0.643 / (Μ/Δ)    | -                     | 0.756 / (Μ/Δ)       |
| `chapter` | 389      | ~0.0026    | 0.370 / 0.4000        | -                     | 0.260 / 0.2800         | -                    | 0.460 / 0.4720     | -                | 0.640 / 0.6600        | -                   |
| `subject` | 2285     | ~0.0004    | 0.270 / 0.3000        | -                     | 0.190 / 0.2100         | -                    | 0.360 / 0.3500     | -                | 0.220 / 0.2400 (20%)  | -                   |


## 4. Συζήτηση και Συμπεράσματα

Όλα τα μοντέλα ξεπέρασαν σημαντικά τον theoretical random baseline classifier.
*   **Απόδοση:** Οι SVMs, ιδιαίτερα με TF-IDF χαρακτηριστικά, έδειξαν την ισχυρότερη απόδοση, ειδικά για την ετικέτα `volume` με 5-fold CV (F1 0.756). Η LogReg με Word2Vec χαρακτηριστικά υπερτέρησε του XGBoost (επίσης με Word2Vec) στις single run αξιολογήσεις για `chapter` (F1 0.370 έναντι 0.260) και `subject` (F1 0.270 έναντι 0.190), πιθανόν λόγω της απλότητας του μοντέλου LogReg ή μη βέλτιστων υπερπαραμέτρων για το XGBoost σε αυτές τις περιπτώσεις. Το XGBoost (CV) στον `volume` έδειξε F1 0.348, υποδεικνύοντας ότι με CV μπορεί να επιτύχει καλύτερη γενίκευση.
*   **Αξιολόγηση:** Η χρήση 5-fold Cross-Validation για την ετικέτα `volume` παρείχε μια πιο στιβαρή εκτίμηση της απόδοσης των μοντέλων σε σύγκριση με το απλό train/test split που χρησιμοποιήθηκε για τις `chapter` και `subject` λόγω υπολογιστικών περιορισμών. Η στρωματοποίηση (stratification) κατά τον διαχωρισμό των δεδομένων και η χρήση `weighted average` για τις μετρικές ήταν σημαντικές για την αντιμετώπιση της ανισορροπίας των κλάσεων.
*   **Περιορισμοί:** Οι χρησιμοποιηθείσες Word2Vec αναπαραστάσεις, αν και αποτελεσματικές σε κάποιο βαθμό, ενδέχεται να μην συλλαμβάνουν πλήρως την πλούσια σημασιολογία των νομικών κειμένων. Επιπλέον, η έλλειψη συστηματικής βελτιστοποίησης υπερπαραμέτρων και η περιορισμένη χρήση CV για τις ετικέτες `chapter` και `subject` αποτελούν περιορισμούς της τρέχουσας μελέτης.

**Συμπέρασμα:** Η παρούσα μελέτη καταδεικνύει τη βιωσιμότητα της χρήσης μοντέλων μηχανικής μάθησης για την ταξινόμηση ελληνικών νομικών εγγράφων στις ετικέτες `volume`, `chapter`, και `subject`. Τα μοντέλα SVM με TF-IDF χαρακτηριστικά επέδειξαν την καλύτερη συνολική απόδοση, ειδικά όταν αξιολογήθηκαν με cross-validation. Η Λογιστική Παλινδρόμηση με Word2Vec αναδείχθηκε ως μια ανταγωνιστική προσέγγιση για τις ετικέτες `chapter` και `subject` σε σενάρια μεμονωμένης εκτέλεσης (single run), ξεπερνώντας το XGBoost υπό τις ίδιες συνθήκες. Παρά τους περιορισμούς, όπως η μη συστηματική βελτιστοποίηση υπερπαραμέτρων και η περιορισμένη χρήση cross-validation για όλες τις ετικέτες, τα αποτελέσματα είναι ενθαρρυντικά και υποδεικνύουν ότι όλα τα μοντέλα μαθαίνουν ουσιαστικά πρότυπα από τα δεδομένα, ξεπερνώντας σημαντικά τον theoretical random baseline classifier. Η χρήση πιο εξελιγμένων τεχνικών αναπαράστασης κειμένου και η εκτεταμένη βελτιστοποίηση υπερπαραμέτρων αναμένεται να βελτιώσουν περαιτέρω την απόδοση.
