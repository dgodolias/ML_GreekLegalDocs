{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5aef71c9",
   "metadata": {},
   "source": [
    "# Β2.ii) Ομαδοποίηση με K-means Clustering\n",
    "\n",
    "Αυτό το notebook εκτελεί την ομαδοποίηση κειμένων με K-means clustering όπως περιγράφεται στην ενότητα Β2.ii της εργασίας.\n",
    "\n",
    "**Κύρια Χαρακτηριστικά:**\n",
    "- **Μοντέλο**: K-means clustering\n",
    "- **Feature Extraction**: TF-IDF vectorization  \n",
    "- **Dataset**: \"DominusTea/GreekLegalSum\" από το Hugging Face Hub\n",
    "- **Στόχος**: Ομαδοποίηση των νομικών κειμένων σε clusters\n",
    "\n",
    "**Διαδικασία:**\n",
    "1. Εύρεση του βέλτιστου αριθμού clusters (K) με χρήση evaluation metrics\n",
    "2. Εφαρμογή του K-means με το επιλεγμένο K\n",
    "3. Ανάλυση και αξιολόγηση των αποτελεσμάτων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a557d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples, normalized_mutual_info_score, adjusted_rand_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0610ddb",
   "metadata": {},
   "source": [
    "## 1. Παραμετροποίηση του Πειράματος\n",
    "\n",
    "Ορισμός των βασικών παραμέτρων για την ομαδοποίηση με K-means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9612fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration για K Selection ---\n",
    "TEXT_COLUMN_TO_USE = 'summary'  # 'summary' or 'text'\n",
    "# Χρησιμοποιούμε 'summary' γιατί είναι γενικά πιο καθαρό και λιγότερο υπολογιστικά εντατικό\n",
    "\n",
    "VECTORIZATION_METHOD = 'tfidf' # TF-IDF είναι συνηθισμένη επιλογή για K-means\n",
    "MIN_K_TO_TEST = 2           # Ελάχιστη τιμή K για test\n",
    "MAX_K_TO_TEST = 50          # Μέγιστη τιμή K για test (μειωμένο για notebook)\n",
    "K_STEP = 2                  # Βήμα για τις τιμές K\n",
    "RANDOM_STATE = 42           # Για αναπαραγωγιμότητα\n",
    "\n",
    "# --- Configuration για Final K-means ---\n",
    "CHOSEN_K = 21               # Θα το ορίσουμε μετά την ανάλυση των metrics\n",
    "OUTPUT_CSV_FILE = '../documents_with_clusters.csv'  # Αρχείο για αποθήκευση αποτελεσμάτων\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"- Text column: {TEXT_COLUMN_TO_USE}\")\n",
    "print(f\"- Vectorization method: {VECTORIZATION_METHOD}\")\n",
    "print(f\"- K range: {MIN_K_TO_TEST} to {MAX_K_TO_TEST} (step: {K_STEP})\")\n",
    "print(f\"- Random state: {RANDOM_STATE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b52c4cd",
   "metadata": {},
   "source": [
    "## 2. Φόρτωση και Προετοιμασία Δεδομένων\n",
    "\n",
    "Φορτώνουμε το dataset \"DominusTea/GreekLegalSum\" και το προετοιμάζουμε για την ανάλυση clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785482f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data():\n",
    "    \"\"\"Loads the dataset and prepares it for analysis.\"\"\"\n",
    "    print(\"Loading the 'DominusTea/GreekLegalSum' dataset...\")\n",
    "    dataset_hf = None\n",
    "    try:\n",
    "        dataset_hf = load_dataset(\"DominusTea/GreekLegalSum\", trust_remote_code=True)\n",
    "        print(\"Dataset object loaded successfully from Hugging Face Hub.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading dataset from Hugging Face Hub: {e}\")\n",
    "        return None\n",
    "\n",
    "    df = None\n",
    "    if dataset_hf:\n",
    "        dataset_split = dataset_hf.get('train')\n",
    "        if dataset_split:\n",
    "            print(\"Using 'train' split.\")\n",
    "            df = dataset_split.to_pandas()\n",
    "        else:\n",
    "            print(\"'train' split not found. Trying the first available split.\")\n",
    "            available_splits = list(dataset_hf.keys())\n",
    "            if available_splits:\n",
    "                split_to_use = available_splits[0]\n",
    "                print(f\"Attempting to use the first available split: '{split_to_use}'\")\n",
    "                try:\n",
    "                    df = dataset_hf[split_to_use].to_pandas()\n",
    "                except Exception as e:\n",
    "                    print(f\"Error converting split '{split_to_use}' to Pandas DataFrame: {e}\")\n",
    "            else:\n",
    "                print(\"No splits available in the loaded dataset object.\")\n",
    "    \n",
    "    if df is None:\n",
    "        print(\"DataFrame could not be created.\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\nDataFrame created. Shape: {df.shape}\")\n",
    "    \n",
    "    # Αντικατάσταση NaN values με κενό string\n",
    "    df[TEXT_COLUMN_TO_USE] = df[TEXT_COLUMN_TO_USE].fillna('')\n",
    "    \n",
    "    print(f\"Data prepared. Using column '{TEXT_COLUMN_TO_USE}' for clustering.\")\n",
    "    return df\n",
    "\n",
    "# Φόρτωση δεδομένων\n",
    "df = load_and_prepare_data()\n",
    "if df is not None:\n",
    "    print(f\"\\nDataset info:\")\n",
    "    print(f\"- Shape: {df.shape}\")\n",
    "    print(f\"- Columns: {list(df.columns)}\")\n",
    "    print(f\"- Non-null values in '{TEXT_COLUMN_TO_USE}': {df[TEXT_COLUMN_TO_USE].notna().sum()}\")\n",
    "else:\n",
    "    print(\"Failed to load data. Cannot proceed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d101f4",
   "metadata": {},
   "source": [
    "## 3. Διανυσματοποίηση Κειμένων\n",
    "\n",
    "Μετατρέπουμε τα κείμενα σε αριθμητικές αναπαραστάσεις χρησιμοποιώντας TF-IDF vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b84b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_texts(texts_series, method='tfidf'):\n",
    "    \"\"\"Vectorizes texts using the specified method.\"\"\"\n",
    "    print(f\"\\nVectorizing texts using {method} on '{TEXT_COLUMN_TO_USE}' column...\")\n",
    "    if method == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            max_df=0.90,    # Αγνοεί terms που εμφανίζονται σε >90% των documents\n",
    "            min_df=5,       # Αγνοεί terms που εμφανίζονται σε <5 documents\n",
    "            ngram_range=(1, 2),  # Unigrams και bigrams\n",
    "            stop_words=None      # Δεν χρησιμοποιούμε predefined stop words για ελληνικά\n",
    "        )\n",
    "        X = vectorizer.fit_transform(texts_series)\n",
    "        print(f\"TF-IDF matrix shape: {X.shape}\")\n",
    "        print(f\"Number of features: {len(vectorizer.get_feature_names_out())}\")\n",
    "        return X, vectorizer\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported vectorization method: {method}\")\n",
    "\n",
    "# Διανυσματοποίηση\n",
    "if df is not None:\n",
    "    X, vectorizer = vectorize_texts(df[TEXT_COLUMN_TO_USE], method=VECTORIZATION_METHOD)\n",
    "    print(f\"\\nVectorization completed.\")\n",
    "    print(f\"Feature matrix shape: {X.shape}\")\n",
    "    print(f\"Matrix sparsity: {(1 - X.nnz / (X.shape[0] * X.shape[1])) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a951af",
   "metadata": {},
   "source": [
    "## 4. Εύρεση Βέλτιστου Αριθμού Clusters (K)\n",
    "\n",
    "Εκτελούμε K-means για διάφορες τιμές του K και υπολογίζουμε evaluation metrics για να βρούμε τη βέλτιστη τιμή.\n",
    "\n",
    "**Metrics που χρησιμοποιούμε:**\n",
    "- **WCSS (Within-Cluster Sum of Squares)**: Για την Elbow Method\n",
    "- **Silhouette Score**: Μετρά πόσο καλά διαχωρισμένα είναι τα clusters\n",
    "- **NMI (Normalized Mutual Information)**: Σύγκριση με τα ground truth labels (case_category, case_tags)\n",
    "- **ARI (Adjusted Rand Index)**: Άλλη μετρική σύγκρισης με ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031712fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans_and_evaluate(X, df, min_k, max_k, k_step):\n",
    "    \"\"\"Runs K-means for a range of K and calculates evaluation metrics.\"\"\"\n",
    "    print(f\"\\nRunning K-means for K from {min_k} to {max_k} with a step of {k_step}...\")\n",
    "    \n",
    "    k_values = list(range(min_k, max_k + 1, k_step))\n",
    "    if not k_values: \n",
    "        if max_k >= min_k:\n",
    "             k_values = [min_k] \n",
    "        else: \n",
    "            print(f\"max_k ({max_k}) is less than min_k ({min_k}), K-means cannot be run.\")\n",
    "            return [], [], [], [], [], [], [], []\n",
    "\n",
    "    wcss = []\n",
    "    silhouette_scores_micro = []\n",
    "    silhouette_scores_macro = []\n",
    "    nmi_category_scores = []\n",
    "    nmi_tags_scores = []\n",
    "    ari_category_scores = [] \n",
    "    ari_tags_scores = []   \n",
    "\n",
    "    true_labels_category_full = df['case_category']\n",
    "    true_labels_tags_full = df['case_tags'] \n",
    "\n",
    "    for k in k_values:\n",
    "        print(f\"  Processing K={k}...\")\n",
    "        kmeans = KMeans(n_clusters=k, init='k-means++', n_init='auto', random_state=RANDOM_STATE)\n",
    "        cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "        # WCSS (Within-Cluster Sum of Squares)\n",
    "        wcss.append(kmeans.inertia_)\n",
    "\n",
    "        # Silhouette Score (micro average)\n",
    "        s_micro = silhouette_score(X, cluster_labels, metric='euclidean')\n",
    "        silhouette_scores_micro.append(s_micro)\n",
    "\n",
    "        # Silhouette Score (macro average - per cluster average)\n",
    "        sample_s_values = silhouette_samples(X, cluster_labels, metric='euclidean')\n",
    "        cluster_avg_s_values = []\n",
    "        for i in range(k): \n",
    "            ith_cluster_s_values = sample_s_values[cluster_labels == i]\n",
    "            if len(ith_cluster_s_values) > 0:\n",
    "                cluster_avg_s_values.append(ith_cluster_s_values.mean())\n",
    "        \n",
    "        if cluster_avg_s_values:\n",
    "            s_macro = np.mean(cluster_avg_s_values)\n",
    "        else:\n",
    "            s_macro = np.nan \n",
    "        silhouette_scores_macro.append(s_macro)\n",
    "        \n",
    "        # NMI και ARI για case_category\n",
    "        valid_indices_category = true_labels_category_full.notna()\n",
    "        if valid_indices_category.sum() >= 2: \n",
    "            nmi_cat = normalized_mutual_info_score(\n",
    "                true_labels_category_full[valid_indices_category],\n",
    "                cluster_labels[valid_indices_category]\n",
    "            )\n",
    "            nmi_category_scores.append(nmi_cat)\n",
    "            ari_cat = adjusted_rand_score( \n",
    "                true_labels_category_full[valid_indices_category],\n",
    "                cluster_labels[valid_indices_category]\n",
    "            )\n",
    "            ari_category_scores.append(ari_cat)\n",
    "        else:\n",
    "            nmi_category_scores.append(np.nan)\n",
    "            ari_category_scores.append(np.nan)\n",
    "\n",
    "        # NMI και ARI για case_tags\n",
    "        valid_indices_tags = true_labels_tags_full.notna()\n",
    "        if valid_indices_tags.sum() >= 2:\n",
    "            nmi_tag = normalized_mutual_info_score(\n",
    "                true_labels_tags_full[valid_indices_tags],\n",
    "                cluster_labels[valid_indices_tags]\n",
    "            )\n",
    "            nmi_tags_scores.append(nmi_tag)\n",
    "            ari_tag = adjusted_rand_score( \n",
    "                true_labels_tags_full[valid_indices_tags],\n",
    "                cluster_labels[valid_indices_tags]\n",
    "            )\n",
    "            ari_tags_scores.append(ari_tag)\n",
    "        else:\n",
    "            nmi_tags_scores.append(np.nan)\n",
    "            ari_tags_scores.append(np.nan)\n",
    "            \n",
    "    return k_values, wcss, silhouette_scores_micro, silhouette_scores_macro, nmi_category_scores, nmi_tags_scores, ari_category_scores, ari_tags_scores\n",
    "\n",
    "# Εκτέλεση evaluation για διάφορες τιμές K\n",
    "if df is not None and 'X' in locals():\n",
    "    k_values, wcss, s_micro, s_macro, nmi_cat, nmi_tag, ari_cat, ari_tag = run_kmeans_and_evaluate(\n",
    "        X, df, MIN_K_TO_TEST, MAX_K_TO_TEST, K_STEP\n",
    "    )\n",
    "    print(f\"\\nEvaluation completed for {len(k_values)} K values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5435a27f",
   "metadata": {},
   "source": [
    "## 5. Οπτικοποίηση Evaluation Metrics\n",
    "\n",
    "Δημιουργούμε γραφήματα για τις διάφορες μετρικές αξιολόγησης που θα μας βοηθήσουν να επιλέξουμε το βέλτιστο K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation_metrics(k_values, wcss, s_micro, s_macro, nmi_cat, nmi_tag, ari_cat, ari_tag):\n",
    "    \"\"\"Plots the evaluation metrics for choosing K.\"\"\"\n",
    "    if not k_values:\n",
    "        print(\"No K values to plot. Skipping plotting.\")\n",
    "        return\n",
    "        \n",
    "    print(\"\\nPlotting evaluation metrics...\")\n",
    "    plt.style.use('seaborn-v0_8-whitegrid') \n",
    "    fig, axs = plt.subplots(2, 2, figsize=(18, 12))\n",
    "    fig.suptitle('K-means Clustering Evaluation Metrics for Optimal K Selection', fontsize=16)\n",
    "\n",
    "    # Elbow Method (WCSS)\n",
    "    axs[0, 0].plot(k_values, wcss, marker='o', linestyle='-', color='dodgerblue')\n",
    "    axs[0, 0].set_title('Elbow Method (WCSS vs. K)', fontsize=14)\n",
    "    axs[0, 0].set_xlabel('Number of Clusters (K)', fontsize=12)\n",
    "    axs[0, 0].set_ylabel('WCSS (Inertia)', fontsize=12)\n",
    "    axs[0, 0].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Silhouette Scores\n",
    "    axs[0, 1].plot(k_values, s_micro, marker='s', linestyle='-', color='mediumseagreen', label='Micro Avg. Silhouette')\n",
    "    axs[0, 1].plot(k_values, s_macro, marker='^', linestyle='--', color='darkorange', label='Macro Avg. Silhouette (per cluster avg.)')\n",
    "    axs[0, 1].set_title('Silhouette Scores vs. K', fontsize=14)\n",
    "    axs[0, 1].set_xlabel('Number of Clusters (K)', fontsize=12)\n",
    "    axs[0, 1].set_ylabel('Silhouette Score', fontsize=12)\n",
    "    axs[0, 1].legend(fontsize=10)\n",
    "    axs[0, 1].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # NMI Scores (Combined on one plot)\n",
    "    axs[1, 0].plot(k_values, nmi_cat, marker='D', linestyle='-', color='crimson', label='NMI vs. Case Category')\n",
    "    axs[1, 0].plot(k_values, nmi_tag, marker='p', linestyle='--', color='purple', label='NMI vs. Case Tags')\n",
    "    axs[1, 0].set_title('NMI Scores vs. K', fontsize=14)\n",
    "    axs[1, 0].set_xlabel('Number of Clusters (K)', fontsize=12)\n",
    "    axs[1, 0].set_ylabel('NMI Score', fontsize=12)\n",
    "    axs[1, 0].legend(fontsize=10)\n",
    "    axs[1, 0].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # ARI Scores (Combined on one plot)\n",
    "    axs[1, 1].plot(k_values, ari_cat, marker='o', linestyle='-', color='teal', label='ARI vs. Case Category')\n",
    "    axs[1, 1].plot(k_values, ari_tag, marker='x', linestyle='--', color='sienna', label='ARI vs. Case Tags')\n",
    "    axs[1, 1].set_title('ARI Scores vs. K', fontsize=14)\n",
    "    axs[1, 1].set_xlabel('Number of Clusters (K)', fontsize=12)\n",
    "    axs[1, 1].set_ylabel('ARI Score', fontsize=12)\n",
    "    axs[1, 1].legend(fontsize=10)\n",
    "    axs[1, 1].grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96]) \n",
    "    plt.show()\n",
    "\n",
    "# Οπτικοποίηση των metrics\n",
    "if 'k_values' in locals() and k_values:\n",
    "    plot_evaluation_metrics(k_values, wcss, s_micro, s_macro, nmi_cat, nmi_tag, ari_cat, ari_tag)\n",
    "    \n",
    "    # Εκτύπωση των αποτελεσμάτων για ανάλυση\n",
    "    print(f\"\\nDetailed Results:\")\n",
    "    print(f\"{'K':<3} {'WCSS':<10} {'Silh_Micro':<12} {'Silh_Macro':<12} {'NMI_Cat':<10} {'NMI_Tag':<10} {'ARI_Cat':<10} {'ARI_Tag':<10}\")\n",
    "    print(\"-\" * 85)\n",
    "    for i, k in enumerate(k_values):\n",
    "        print(f\"{k:<3} {wcss[i]:<10.2f} {s_micro[i]:<12.4f} {s_macro[i]:<12.4f} \"\n",
    "              f\"{nmi_cat[i]:<10.4f} {nmi_tag[i]:<10.4f} {ari_cat[i]:<10.4f} {ari_tag[i]:<10.4f}\")\n",
    "else:\n",
    "    print(\"No evaluation results to plot.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93176674",
   "metadata": {},
   "source": [
    "## 6. Επιλογή Βέλτιστου K και Τελική Ομαδοποίηση\n",
    "\n",
    "Με βάση τα γραφήματα και τις μετρικές, επιλέγουμε το βέλτιστο K και εκτελούμε την τελική ομαδοποίηση.\n",
    "\n",
    "**Κριτήρια επιλογής K:**\n",
    "- **Elbow Method**: Αναζητούμε το σημείο όπου η μείωση του WCSS επιβραδύνεται\n",
    "- **Silhouette Score**: Επιλέγουμε K που μεγιστοποιεί το silhouette score\n",
    "- **NMI/ARI**: Εξετάζουμε την ταύτιση με τα ground truth labels\n",
    "- **Ερμηνευσιμότητα**: Το K πρέπει να είναι λογικό για την εφαρμογή"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1030747",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_final_kmeans(X, df_input, chosen_k_value):\n",
    "    \"\"\"Runs K-means for the chosen K, evaluates, and adds labels to DataFrame.\"\"\"\n",
    "    df = df_input.copy()  # Δουλεύουμε σε αντίγραφο για να μην τροποποιήσουμε το original\n",
    "    print(f\"\\nRunning K-means for the chosen K = {chosen_k_value}...\")\n",
    "    \n",
    "    kmeans_model = KMeans(n_clusters=chosen_k_value, init='k-means++', n_init='auto', random_state=RANDOM_STATE)\n",
    "    cluster_labels = kmeans_model.fit_predict(X)\n",
    "\n",
    "    # Προσθήκη cluster labels στο DataFrame\n",
    "    df['cluster_id'] = cluster_labels\n",
    "    print(f\"\\nCluster labels added to DataFrame in column 'cluster_id'.\")\n",
    "\n",
    "    # Ανάλυση των cluster sizes\n",
    "    print(\"\\n--- Cluster Sizes ---\")\n",
    "    cluster_sizes = df['cluster_id'].value_counts().sort_index()\n",
    "    for cluster_id_val, size in cluster_sizes.items():\n",
    "        print(f\"  Cluster {cluster_id_val}: {size} documents ({size/len(df)*100:.1f}%)\")\n",
    "        \n",
    "    # Υπολογισμός τελικών metrics\n",
    "    final_silhouette = silhouette_score(X, cluster_labels, metric='euclidean')\n",
    "    print(f\"\\nFinal Silhouette Score: {final_silhouette:.4f}\")\n",
    "    \n",
    "    # Ανάλυση σχέσης με ground truth (αν υπάρχουν)\n",
    "    valid_category_mask = df['case_category'].notna()\n",
    "    if valid_category_mask.sum() > 1:\n",
    "        final_nmi_cat = normalized_mutual_info_score(\n",
    "            df.loc[valid_category_mask, 'case_category'],\n",
    "            df.loc[valid_category_mask, 'cluster_id']\n",
    "        )\n",
    "        final_ari_cat = adjusted_rand_score(\n",
    "            df.loc[valid_category_mask, 'case_category'],\n",
    "            df.loc[valid_category_mask, 'cluster_id']\n",
    "        )\n",
    "        print(f\"NMI with case_category: {final_nmi_cat:.4f}\")\n",
    "        print(f\"ARI with case_category: {final_ari_cat:.4f}\")\n",
    "    \n",
    "    return df, kmeans_model\n",
    "\n",
    "# Εκτέλεση τελικής ομαδοποίησης\n",
    "if df is not None and 'X' in locals():\n",
    "    # Αν θέλουμε να αλλάξουμε το K με βάση τα αποτελέσματα, μπορούμε να το κάνουμε εδώ\n",
    "    print(f\"\\nUsing K = {CHOSEN_K} for final clustering...\")\n",
    "    \n",
    "    df_with_clusters, kmeans_model = run_final_kmeans(X, df, CHOSEN_K)\n",
    "    \n",
    "    print(f\"\\nFinal clustering completed with {CHOSEN_K} clusters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c34440",
   "metadata": {},
   "source": [
    "## 7. Ανάλυση και Χαρακτηρισμός των Clusters\n",
    "\n",
    "Αναλύουμε τα περιεχόμενα των clusters και εξάγουμε χαρακτηριστικά για κάθε ομάδα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62908fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_clusters(df_clustered, vectorizer, kmeans_model, n_top_terms=10):\n",
    "    \"\"\"Analyzes the content of each cluster.\"\"\"\n",
    "    print(f\"\\n--- Cluster Content Analysis ---\")\n",
    "    \n",
    "    # Εξαγωγή των top terms για κάθε cluster από τα centroids\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    centroids = kmeans_model.cluster_centers_\n",
    "    \n",
    "    cluster_top_terms = {}\n",
    "    \n",
    "    for cluster_id in range(len(centroids)):\n",
    "        # Παίρνουμε τα indices των top terms για αυτό το cluster\n",
    "        top_indices = centroids[cluster_id].argsort()[-n_top_terms:][::-1]\n",
    "        top_terms = [feature_names[i] for i in top_indices]\n",
    "        top_weights = [centroids[cluster_id][i] for i in top_indices]\n",
    "        \n",
    "        cluster_top_terms[cluster_id] = list(zip(top_terms, top_weights))\n",
    "        \n",
    "        print(f\"\\nCluster {cluster_id} (Size: {(df_clustered['cluster_id'] == cluster_id).sum()}):\")\n",
    "        print(\"Top terms:\", \", \".join([f\"{term}({weight:.3f})\" for term, weight in cluster_top_terms[cluster_id]]))\n",
    "        \n",
    "        # Παραδείγματα κειμένων από το cluster\n",
    "        cluster_docs = df_clustered[df_clustered['cluster_id'] == cluster_id]\n",
    "        if len(cluster_docs) > 0:\n",
    "            print(\"Sample documents:\")\n",
    "            for i, (idx, row) in enumerate(cluster_docs.head(2).iterrows()):\n",
    "                summary_text = row[TEXT_COLUMN_TO_USE][:200] + \"...\" if len(row[TEXT_COLUMN_TO_USE]) > 200 else row[TEXT_COLUMN_TO_USE]\n",
    "                print(f\"  {i+1}. {summary_text}\")\n",
    "    \n",
    "    return cluster_top_terms\n",
    "\n",
    "# Ανάλυση clusters\n",
    "if 'df_with_clusters' in locals() and 'vectorizer' in locals() and 'kmeans_model' in locals():\n",
    "    cluster_terms = analyze_clusters(df_with_clusters, vectorizer, kmeans_model, n_top_terms=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fce14f",
   "metadata": {},
   "source": [
    "## 8. Οπτικοποίηση Cluster Distribution\n",
    "\n",
    "Δημιουργούμε οπτικοποιήσεις για την κατανομή των clusters και τη σχέση τους με τα ground truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3bb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cluster_results(df_clustered):\n",
    "    \"\"\"Creates visualizations for cluster analysis.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('K-means Clustering Results Analysis', fontsize=16)\n",
    "    \n",
    "    # 1. Cluster size distribution\n",
    "    cluster_counts = df_clustered['cluster_id'].value_counts().sort_index()\n",
    "    axes[0, 0].bar(cluster_counts.index, cluster_counts.values, color='lightblue', edgecolor='navy')\n",
    "    axes[0, 0].set_title('Cluster Size Distribution')\n",
    "    axes[0, 0].set_xlabel('Cluster ID')\n",
    "    axes[0, 0].set_ylabel('Number of Documents')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Cluster sizes as pie chart\n",
    "    axes[0, 1].pie(cluster_counts.values, labels=cluster_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "    axes[0, 1].set_title('Cluster Size Proportions')\n",
    "    \n",
    "    # 3. Relationship with case_category (if available)\n",
    "    valid_category_data = df_clustered[df_clustered['case_category'].notna()]\n",
    "    if len(valid_category_data) > 0:\n",
    "        # Heatmap των top categories ανά cluster\n",
    "        category_cluster_counts = valid_category_data.groupby(['cluster_id', 'case_category']).size().unstack(fill_value=0)\n",
    "        \n",
    "        # Παίρνουμε μόνο τις top 10 categories για καλύτερη οπτικοποίηση\n",
    "        top_categories = valid_category_data['case_category'].value_counts().head(10).index\n",
    "        category_cluster_subset = category_cluster_counts[top_categories]\n",
    "        \n",
    "        sns.heatmap(category_cluster_subset.T, annot=True, fmt='d', cmap='Blues', ax=axes[1, 0])\n",
    "        axes[1, 0].set_title('Cluster vs Top Case Categories')\n",
    "        axes[1, 0].set_xlabel('Cluster ID')\n",
    "        axes[1, 0].set_ylabel('Case Category')\n",
    "    else:\n",
    "        axes[1, 0].text(0.5, 0.5, 'No case_category data available', \n",
    "                       horizontalalignment='center', verticalalignment='center')\n",
    "        axes[1, 0].set_title('Cluster vs Case Categories (No Data)')\n",
    "    \n",
    "    # 4. Document length distribution per cluster\n",
    "    if TEXT_COLUMN_TO_USE in df_clustered.columns:\n",
    "        df_clustered['text_length'] = df_clustered[TEXT_COLUMN_TO_USE].str.len()\n",
    "        \n",
    "        # Box plot για text lengths ανά cluster\n",
    "        cluster_lengths = []\n",
    "        cluster_labels = []\n",
    "        for cluster_id in sorted(df_clustered['cluster_id'].unique()):\n",
    "            cluster_docs = df_clustered[df_clustered['cluster_id'] == cluster_id]\n",
    "            cluster_lengths.append(cluster_docs['text_length'].values)\n",
    "            cluster_labels.append(f'C{cluster_id}')\n",
    "        \n",
    "        axes[1, 1].boxplot(cluster_lengths, labels=cluster_labels)\n",
    "        axes[1, 1].set_title('Text Length Distribution by Cluster')\n",
    "        axes[1, 1].set_xlabel('Cluster ID')\n",
    "        axes[1, 1].set_ylabel('Text Length (characters)')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    else:\n",
    "        axes[1, 1].text(0.5, 0.5, 'Text length analysis not available', \n",
    "                       horizontalalignment='center', verticalalignment='center')\n",
    "        axes[1, 1].set_title('Text Length Distribution (No Data)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Οπτικοποίηση αποτελεσμάτων\n",
    "if 'df_with_clusters' in locals():\n",
    "    visualize_cluster_results(df_with_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d93d2cf",
   "metadata": {},
   "source": [
    "## 9. Αποθήκευση Αποτελεσμάτων\n",
    "\n",
    "Αποθηκεύουμε το DataFrame με τα cluster assignments σε CSV αρχείο για περαιτέρω ανάλυση."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daf03ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(df_clustered, output_file):\n",
    "    \"\"\"Saves the DataFrame with cluster assignments to CSV.\"\"\"\n",
    "    try:\n",
    "        # Δημιουργία του directory αν δεν υπάρχει\n",
    "        output_dir = os.path.dirname(output_file)\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            print(f\"Created directory: {output_dir}\")\n",
    "\n",
    "        # Αποθήκευση σε CSV\n",
    "        df_clustered.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nDataFrame with cluster assignments saved to '{os.path.abspath(output_file)}'\")\n",
    "        \n",
    "        # Σύνοψη των αποτελεσμάτων\n",
    "        print(f\"\\nResults Summary:\")\n",
    "        print(f\"- Total documents: {len(df_clustered)}\")\n",
    "        print(f\"- Number of clusters: {df_clustered['cluster_id'].nunique()}\")\n",
    "        print(f\"- Output file: {os.path.abspath(output_file)}\")\n",
    "        \n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError saving DataFrame to CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "# Αποθήκευση αποτελεσμάτων\n",
    "if 'df_with_clusters' in locals():\n",
    "    success = save_results(df_with_clusters, OUTPUT_CSV_FILE)\n",
    "    if success:\n",
    "        print(f\"\\nClustering process completed successfully!\")\n",
    "        print(f\"The file '{OUTPUT_CSV_FILE}' contains all documents with their assigned cluster IDs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c970a2",
   "metadata": {},
   "source": [
    "## 10. Συμπεράσματα και Παρατηρήσεις\n",
    "\n",
    "### Αποτελέσματα της Ομαδοποίησης\n",
    "\n",
    "Βασισμένα στην ανάλυση που πραγματοποιήσαμε:\n",
    "\n",
    "**Τεχνικά Χαρακτηριστικά:**\n",
    "- **Dataset**: \"DominusTea/GreekLegalSum\" με χρήση του πεδίου 'summary'\n",
    "- **Vectorization**: TF-IDF με παραμέτρους max_df=0.90, min_df=5, ngram_range=(1,2)\n",
    "- **Clustering Algorithm**: K-means με k-means++ initialization\n",
    "- **Επιλεγμένο K**: 21 clusters\n",
    "\n",
    "**Αξιολόγηση των Αποτελεσμάτων:**\n",
    "- **Silhouette Score**: Μετρά την ποιότητα των clusters σε όρους εσωτερικής συνοχής και διαχωρισμού\n",
    "- **NMI/ARI vs Ground Truth**: Εξετάζει πόσο καλά τα clusters ταιριάζουν με τις υπάρχουσες κατηγορίες\n",
    "\n",
    "**Παρατηρήσεις:**\n",
    "1. **Cluster Distribution**: Η κατανομή των μεγεθών των clusters δείχνει...\n",
    "2. **Θεματική Συνοχή**: Τα top terms κάθε cluster υποδηλώνουν...\n",
    "3. **Σχέση με Ground Truth**: Η σύγκριση με τις υπάρχουσες κατηγορίες αποκαλύπτει...\n",
    "\n",
    "**Πιθανές Βελτιώσεις:**\n",
    "- Χρήση διαφορετικών vectorization τεχνικών (Word2Vec, Doc2Vec, BERT embeddings)\n",
    "- Εφαρμογή άλλων clustering αλγορίθμων (Hierarchical, DBSCAN)\n",
    "- Pre-processing βελτιώσεις (stemming, lemmatization για ελληνικά)\n",
    "- Feature selection για μείωση της διαστατικότητας\n",
    "\n",
    "Η ομαδοποίηση των νομικών κειμένων παρέχει πολύτιμες γνώσεις για την οργάνωση και κατηγοριοποίηση του νομικού περιεχομένου, και μπορεί να χρησιμοποιηθεί για περαιτέρω ανάλυση και εφαρμογές στον τομέα της νομικής επιστήμης."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
